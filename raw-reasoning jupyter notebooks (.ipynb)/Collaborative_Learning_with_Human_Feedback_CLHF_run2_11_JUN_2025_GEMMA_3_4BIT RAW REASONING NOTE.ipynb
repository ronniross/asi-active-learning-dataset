{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "733aae30c8114d3788ab90aaf0ad643e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b00e44e1e8249a895011ebead40f230",
              "IPY_MODEL_82ecf62ad68e4cc4b356040eb4294a1f",
              "IPY_MODEL_f8fc2444744c489ba02ec4ffc4f4f761"
            ],
            "layout": "IPY_MODEL_92fcc1d4472f41329b7d779f9ddb53d9"
          }
        },
        "3b00e44e1e8249a895011ebead40f230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c54be057d94933b663306c88c6ac01",
            "placeholder": "​",
            "style": "IPY_MODEL_0554778699de416dbfb37fe22ac9b2f8",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "82ecf62ad68e4cc4b356040eb4294a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7820afaea0940458fe0edc39a29a982",
            "max": 258351,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffb51a9f86cd427c9522d5f7c5623f3f",
            "value": 258351
          }
        },
        "f8fc2444744c489ba02ec4ffc4f4f761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4ff02faeef46fd8f45fb6eeb757186",
            "placeholder": "​",
            "style": "IPY_MODEL_bf858fee3abe4f6196d7ff3434a68185",
            "value": " 258k/258k [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "92fcc1d4472f41329b7d779f9ddb53d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c54be057d94933b663306c88c6ac01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0554778699de416dbfb37fe22ac9b2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7820afaea0940458fe0edc39a29a982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb51a9f86cd427c9522d5f7c5623f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad4ff02faeef46fd8f45fb6eeb757186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf858fee3abe4f6196d7ff3434a68185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc1a4f684f114ae6b8a1921ee523735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8697771f55241aea9b35bb405cf1dac",
              "IPY_MODEL_9ef8411254fd4018ad21698642b292eb",
              "IPY_MODEL_770b3ea9a1264637862cb34745b605fd"
            ],
            "layout": "IPY_MODEL_323ccb034c8d4ae8a799eb436a916281"
          }
        },
        "f8697771f55241aea9b35bb405cf1dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f180b9e777694002af69d68be04da5e8",
            "placeholder": "​",
            "style": "IPY_MODEL_226ccc151dc34e6f93288d00203092fa",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "9ef8411254fd4018ad21698642b292eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2c855b553d44a2a7b2d31b226e2d96",
            "max": 4955527760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_667d819c1fba493e85a757829bde20b0",
            "value": 4955527760
          }
        },
        "770b3ea9a1264637862cb34745b605fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4e5be7131e54301b5ad3a84c96b694e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6060cf2e1e401586c0fbf146057cc5",
            "value": " 4.96G/4.96G [00:14&lt;00:00, 414MB/s]"
          }
        },
        "323ccb034c8d4ae8a799eb436a916281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f180b9e777694002af69d68be04da5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226ccc151dc34e6f93288d00203092fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf2c855b553d44a2a7b2d31b226e2d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667d819c1fba493e85a757829bde20b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4e5be7131e54301b5ad3a84c96b694e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6060cf2e1e401586c0fbf146057cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2030ec5da250442facb852685ee037ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62eadb6e96824260bc1e719562f7b30c",
              "IPY_MODEL_cbc9ec41651a4552b30d54781d77c476",
              "IPY_MODEL_00a087fda1b740009990082fe49cbd1d"
            ],
            "layout": "IPY_MODEL_a074194edf1e4665bce992d581ea79b3"
          }
        },
        "62eadb6e96824260bc1e719562f7b30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120aaaf60a36421baad281e35bba3e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_daf0847102c64a96b436ef860c061824",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "cbc9ec41651a4552b30d54781d77c476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b31d2bf81d6418f9b07bd409ae7362b",
            "max": 4975309932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c1bcd836ee44198cfda5ead9a200f9",
            "value": 4975309932
          }
        },
        "00a087fda1b740009990082fe49cbd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457956b45cea4f78a5decde481b24baf",
            "placeholder": "​",
            "style": "IPY_MODEL_82e08dc1a8be4a1aa34f63f1596c5fde",
            "value": " 4.98G/4.98G [00:13&lt;00:00, 651MB/s]"
          }
        },
        "a074194edf1e4665bce992d581ea79b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120aaaf60a36421baad281e35bba3e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf0847102c64a96b436ef860c061824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b31d2bf81d6418f9b07bd409ae7362b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c1bcd836ee44198cfda5ead9a200f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "457956b45cea4f78a5decde481b24baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e08dc1a8be4a1aa34f63f1596c5fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e35c1c77eaaa469189e18bd8a0b0eaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f627ea0c83b44074b7b9b76e4590b371",
              "IPY_MODEL_58eb33b9f3944cfaa65a059f64351da0",
              "IPY_MODEL_cba4dfe2b05c4061a0b9fab5d9885ff2"
            ],
            "layout": "IPY_MODEL_31919a16066340c5a672dbe973fd27a9"
          }
        },
        "f627ea0c83b44074b7b9b76e4590b371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f3aa6155e84c7282a073c775163e9a",
            "placeholder": "​",
            "style": "IPY_MODEL_c776e2f1c8134bd0af38d54702c5916d",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "58eb33b9f3944cfaa65a059f64351da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d066c5eb4558499aa8837242fed79161",
            "max": 2836985436,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f6a2e04f17a4235a7bfd46c54ebe671",
            "value": 2836985436
          }
        },
        "cba4dfe2b05c4061a0b9fab5d9885ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ddc3f9b1bec485d86cad982286d08d0",
            "placeholder": "​",
            "style": "IPY_MODEL_253144b8202a4dcb81343907110f417c",
            "value": " 2.84G/2.84G [00:14&lt;00:00, 170MB/s]"
          }
        },
        "31919a16066340c5a672dbe973fd27a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f3aa6155e84c7282a073c775163e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c776e2f1c8134bd0af38d54702c5916d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d066c5eb4558499aa8837242fed79161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f6a2e04f17a4235a7bfd46c54ebe671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ddc3f9b1bec485d86cad982286d08d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253144b8202a4dcb81343907110f417c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbc9cec84db7457cb8204ed90c4beaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0485174fb86d4ae3a5d64c06e90a1e21",
              "IPY_MODEL_6d018f01a779477d89f780ececb2f154",
              "IPY_MODEL_1c3f3be2fe344ab084539c1c24383e9f"
            ],
            "layout": "IPY_MODEL_4a9607debba441fbabfcb51d3acd85a2"
          }
        },
        "0485174fb86d4ae3a5d64c06e90a1e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a633902c6474d6ba10bc9cf00060e92",
            "placeholder": "​",
            "style": "IPY_MODEL_08d294d5aff9402fb747ffbff7812ed3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6d018f01a779477d89f780ececb2f154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256edac34d884638b3ad751b6f8ea5f0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81479dcf277945bbb44fa944b74f9e56",
            "value": 3
          }
        },
        "1c3f3be2fe344ab084539c1c24383e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5dc978f6e1468695a3c702666f6eb7",
            "placeholder": "​",
            "style": "IPY_MODEL_bf2ac0f4b2674e588c80db727063e9c2",
            "value": " 3/3 [00:04&lt;00:00,  1.45s/it]"
          }
        },
        "4a9607debba441fbabfcb51d3acd85a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a633902c6474d6ba10bc9cf00060e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d294d5aff9402fb747ffbff7812ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256edac34d884638b3ad751b6f8ea5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81479dcf277945bbb44fa944b74f9e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab5dc978f6e1468695a3c702666f6eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2ac0f4b2674e588c80db727063e9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b18f870a71d640ddb7affc7f7f7febaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_858339c8fae8484ab3ef753e3e9f956e",
              "IPY_MODEL_c01df05415a54bd59596ea3224e58efc",
              "IPY_MODEL_e8b3e18f36884030a0fd8bea031c107c"
            ],
            "layout": "IPY_MODEL_d1779b17aec949789b80e997e092ac6b"
          }
        },
        "858339c8fae8484ab3ef753e3e9f956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a977f59e544dae9fae72c8f7a76be2",
            "placeholder": "​",
            "style": "IPY_MODEL_d2802932e6aa42e383f8588ef0566449",
            "value": "generation_config.json: 100%"
          }
        },
        "c01df05415a54bd59596ea3224e58efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15601b20c678459383cc252483721171",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_568583669d4b42848588ce2b04c1fd5e",
            "value": 210
          }
        },
        "e8b3e18f36884030a0fd8bea031c107c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f4dfcad3734a94aea93bf6fad923eb",
            "placeholder": "​",
            "style": "IPY_MODEL_6b0463a781974198af469ba66ababd39",
            "value": " 210/210 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "d1779b17aec949789b80e997e092ac6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a977f59e544dae9fae72c8f7a76be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2802932e6aa42e383f8588ef0566449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15601b20c678459383cc252483721171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568583669d4b42848588ce2b04c1fd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64f4dfcad3734a94aea93bf6fad923eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0463a781974198af469ba66ababd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e253cc7312b457b9e513bef767da38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c469a91677f4282adf602a86d8b202a",
              "IPY_MODEL_9ba840ef411b47909a63289f37bb06f3",
              "IPY_MODEL_e0b1c3e807604308bab53e44589e2ff9"
            ],
            "layout": "IPY_MODEL_36f1aff2b3604e8996dd5daa5c178ca2"
          }
        },
        "0c469a91677f4282adf602a86d8b202a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f44de07fb34b30a87dea573e308b69",
            "placeholder": "​",
            "style": "IPY_MODEL_e03f803f9564431d916986177973d68e",
            "value": "processor_config.json: 100%"
          }
        },
        "9ba840ef411b47909a63289f37bb06f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440f14fd4a6a44b78e1ab2b291eaf771",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c6ac9855c447959a7e7cdaeab02dae",
            "value": 70
          }
        },
        "e0b1c3e807604308bab53e44589e2ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7cf8af15e354f2e8e84006ec5f4757c",
            "placeholder": "​",
            "style": "IPY_MODEL_e282f52c72e549a5b3e43d6fabfa56d6",
            "value": " 70.0/70.0 [00:00&lt;00:00, 9.18kB/s]"
          }
        },
        "36f1aff2b3604e8996dd5daa5c178ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f44de07fb34b30a87dea573e308b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03f803f9564431d916986177973d68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440f14fd4a6a44b78e1ab2b291eaf771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c6ac9855c447959a7e7cdaeab02dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7cf8af15e354f2e8e84006ec5f4757c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e282f52c72e549a5b3e43d6fabfa56d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bef51d2a69774c9ba2ad1cb8a8951544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9257bde3f06d4d4da932f22fc4aa6d3e",
              "IPY_MODEL_fb4f902908dd4af0ab2f7255fa4c6620",
              "IPY_MODEL_5450985f0a0e4195a2066db055448821"
            ],
            "layout": "IPY_MODEL_97d160f135b946d2ac0f005f5b40db25"
          }
        },
        "9257bde3f06d4d4da932f22fc4aa6d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab757ba1eb04ec6bc6ba874f30faa74",
            "placeholder": "​",
            "style": "IPY_MODEL_e7143b95281b4ad79b402a536795e49f",
            "value": "chat_template.json: 100%"
          }
        },
        "fb4f902908dd4af0ab2f7255fa4c6620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b18f9087b274dbc9a0f7ad53a4f8026",
            "max": 1615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1868a4a9eaac41ae88e2c214f1e5f3ae",
            "value": 1615
          }
        },
        "5450985f0a0e4195a2066db055448821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2082d6a0226446719bca8ff26ed7a6f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c5b8c93297ef40699d3305a5542a4d0d",
            "value": " 1.61k/1.61k [00:00&lt;00:00, 204kB/s]"
          }
        },
        "97d160f135b946d2ac0f005f5b40db25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab757ba1eb04ec6bc6ba874f30faa74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7143b95281b4ad79b402a536795e49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b18f9087b274dbc9a0f7ad53a4f8026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1868a4a9eaac41ae88e2c214f1e5f3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2082d6a0226446719bca8ff26ed7a6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b8c93297ef40699d3305a5542a4d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b383e95d4ed4f66aee6302a0ecc5afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d127788c4c54511806a1cb1bdabded0",
              "IPY_MODEL_daa4b9d662f847758549c62526cb1ad0",
              "IPY_MODEL_fed9fe504dbc4920a7cb4f5e2d0eb96e"
            ],
            "layout": "IPY_MODEL_870af5b42694480eaa702bd069bdfe2d"
          }
        },
        "5d127788c4c54511806a1cb1bdabded0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01eefebebd5545c8bb0d32822bb887f4",
            "placeholder": "​",
            "style": "IPY_MODEL_0309ff4c447f463194e4b9c6d534fd3c",
            "value": "chat_template.jinja: 100%"
          }
        },
        "daa4b9d662f847758549c62526cb1ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5963505a86c484e98bf4c2c2abe2792",
            "max": 1532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_394074661ef147a89ceaa8d3f5fe8f22",
            "value": 1532
          }
        },
        "fed9fe504dbc4920a7cb4f5e2d0eb96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed17001d38d546a299631ca3a718d6e2",
            "placeholder": "​",
            "style": "IPY_MODEL_9097b5ee9c3f491b810ead259da24593",
            "value": " 1.53k/1.53k [00:00&lt;00:00, 189kB/s]"
          }
        },
        "870af5b42694480eaa702bd069bdfe2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01eefebebd5545c8bb0d32822bb887f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0309ff4c447f463194e4b9c6d534fd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5963505a86c484e98bf4c2c2abe2792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394074661ef147a89ceaa8d3f5fe8f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed17001d38d546a299631ca3a718d6e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9097b5ee9c3f491b810ead259da24593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a8e24f4db814fcc922c8df505c5a906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f96c53028237497599d25feab11b1203",
              "IPY_MODEL_832e12fe34f943b7af495f9d40aa79bb",
              "IPY_MODEL_f5b6d1de7b814620bb96cbb0bdbefd6e"
            ],
            "layout": "IPY_MODEL_63c6aea7f356467d8f5a55836b746740"
          }
        },
        "f96c53028237497599d25feab11b1203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faea30fae2d04f908ab1b0a0ce5edaf9",
            "placeholder": "​",
            "style": "IPY_MODEL_d97e0272265b42c3ae98fd404276817e",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "832e12fe34f943b7af495f9d40aa79bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311c568eee3f46fa9bab3216603de416",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a5af109b1194935839a4c475fba64b1",
            "value": 570
          }
        },
        "f5b6d1de7b814620bb96cbb0bdbefd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4870b334d624b16adfad3d695cfa6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_3c989278435e4fba8fd829aec0e1bacb",
            "value": " 570/570 [00:00&lt;00:00, 68.2kB/s]"
          }
        },
        "63c6aea7f356467d8f5a55836b746740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faea30fae2d04f908ab1b0a0ce5edaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97e0272265b42c3ae98fd404276817e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311c568eee3f46fa9bab3216603de416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5af109b1194935839a4c475fba64b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4870b334d624b16adfad3d695cfa6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c989278435e4fba8fd829aec0e1bacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638e1133e599401c8739ade084ed86d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2f7b95716f646b7a764a06712a6c88a",
              "IPY_MODEL_d557c5837179405a90090a2249c4f3a1",
              "IPY_MODEL_06d4e8d8df9e4d519542cbb3b98917db"
            ],
            "layout": "IPY_MODEL_71cbab949fd94e67890c978028779ac4"
          }
        },
        "f2f7b95716f646b7a764a06712a6c88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ecadc5d2d7c41c6bee9ee73090b2fd9",
            "placeholder": "​",
            "style": "IPY_MODEL_968a81ed5f2a4ed181aa8e017fc2b45a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d557c5837179405a90090a2249c4f3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcb9d02c18e4cb7a6937c77b0c29596",
            "max": 1158492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe18d2e0db9d4b549fab46b05f6a6e1b",
            "value": 1158492
          }
        },
        "06d4e8d8df9e4d519542cbb3b98917db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93625014f93c4227ab3ac0d260175b3b",
            "placeholder": "​",
            "style": "IPY_MODEL_5726ec7ba2714ac7aa30809aabc8d5d7",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 2.28MB/s]"
          }
        },
        "71cbab949fd94e67890c978028779ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecadc5d2d7c41c6bee9ee73090b2fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968a81ed5f2a4ed181aa8e017fc2b45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcb9d02c18e4cb7a6937c77b0c29596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe18d2e0db9d4b549fab46b05f6a6e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93625014f93c4227ab3ac0d260175b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5726ec7ba2714ac7aa30809aabc8d5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f888440695e4a33a8f0d64d48af622f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bd96188684340ae87fffb76119af3d9",
              "IPY_MODEL_9ec0fbe505364d2fb60d25d19db7def9",
              "IPY_MODEL_967fda5dd1cf40f2b7cebc548fefe791"
            ],
            "layout": "IPY_MODEL_6b4a98944a504f8e9727c48862a0730b"
          }
        },
        "7bd96188684340ae87fffb76119af3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2a9130d43543b2aca8efedbee18989",
            "placeholder": "​",
            "style": "IPY_MODEL_7c15ff833eb749359c5bc3711313b218",
            "value": "tokenizer.model: 100%"
          }
        },
        "9ec0fbe505364d2fb60d25d19db7def9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e65c63ca32894368b7ca20b1192503d2",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00ffda0754e7466ab797b7b7c6b8f57d",
            "value": 4689074
          }
        },
        "967fda5dd1cf40f2b7cebc548fefe791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b614140dda0a4f3dac74c768d1286980",
            "placeholder": "​",
            "style": "IPY_MODEL_92dc4cf539bb456da4ddd1e15eac52c4",
            "value": " 4.69M/4.69M [00:01&lt;00:00, 2.91MB/s]"
          }
        },
        "6b4a98944a504f8e9727c48862a0730b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2a9130d43543b2aca8efedbee18989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c15ff833eb749359c5bc3711313b218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e65c63ca32894368b7ca20b1192503d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ffda0754e7466ab797b7b7c6b8f57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b614140dda0a4f3dac74c768d1286980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92dc4cf539bb456da4ddd1e15eac52c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee830cacc64b4555934f7508c2685061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7be265dd54874ebcafa23566c45897b8",
              "IPY_MODEL_22aa99a410444804877463af2b8de055",
              "IPY_MODEL_56265dcbec0b43c790da01775ed47d38"
            ],
            "layout": "IPY_MODEL_2cedf8a7f1d64029bd4c9de4908e6f4e"
          }
        },
        "7be265dd54874ebcafa23566c45897b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872ae8165c2b40e1acf800587d1233fb",
            "placeholder": "​",
            "style": "IPY_MODEL_a9b56e99e0154e0daaf7560f6acd4a53",
            "value": "tokenizer.json: 100%"
          }
        },
        "22aa99a410444804877463af2b8de055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce074eda8c343959eeff17234c5d0cc",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_169c1973b2a741bcb64f048dab60cc44",
            "value": 33384568
          }
        },
        "56265dcbec0b43c790da01775ed47d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f8a4a632d04c5ba6e00e1381b0d0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4b792f39f6a849f2884b97bde0b2a2fb",
            "value": " 33.4M/33.4M [00:02&lt;00:00, 11.5MB/s]"
          }
        },
        "2cedf8a7f1d64029bd4c9de4908e6f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872ae8165c2b40e1acf800587d1233fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b56e99e0154e0daaf7560f6acd4a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce074eda8c343959eeff17234c5d0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169c1973b2a741bcb64f048dab60cc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38f8a4a632d04c5ba6e00e1381b0d0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b792f39f6a849f2884b97bde0b2a2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d031d4d62ec42edafe59947586fa3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e039aa74bd224ab59394b33926c5e776",
              "IPY_MODEL_f66b6e07233645c1af931354de158016",
              "IPY_MODEL_a529c0c01d0643c68a7e4f4d1895ba28"
            ],
            "layout": "IPY_MODEL_f8b843fb11d24b8396a2cc3835a0645d"
          }
        },
        "e039aa74bd224ab59394b33926c5e776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a607cfcb6ad4c8eb8966f78feb62b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_affa9599567945548a7e27ea5101adbc",
            "value": "added_tokens.json: 100%"
          }
        },
        "f66b6e07233645c1af931354de158016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9eff09085c04ce291b42c9b08a2cdbe",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a698b4084d7c4f219e02253c1579f9c6",
            "value": 35
          }
        },
        "a529c0c01d0643c68a7e4f4d1895ba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e93f08fecf4892a052017e3d29808e",
            "placeholder": "​",
            "style": "IPY_MODEL_5650416d0e214874af3ab3b4f6f55fc2",
            "value": " 35.0/35.0 [00:00&lt;00:00, 4.04kB/s]"
          }
        },
        "f8b843fb11d24b8396a2cc3835a0645d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a607cfcb6ad4c8eb8966f78feb62b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affa9599567945548a7e27ea5101adbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9eff09085c04ce291b42c9b08a2cdbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a698b4084d7c4f219e02253c1579f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01e93f08fecf4892a052017e3d29808e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5650416d0e214874af3ab3b4f6f55fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "980eac77904747c6beb7d3b64b14b027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_190a4b85ca2b449eb68a4e932d097084",
              "IPY_MODEL_3cf08d7c6d4a445392102b1be12ef3f0",
              "IPY_MODEL_33064d8cf4534d368d4c5358fb53d472"
            ],
            "layout": "IPY_MODEL_151fa342d7e6450d8e98563b106b49b9"
          }
        },
        "190a4b85ca2b449eb68a4e932d097084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962d0c46ec6b4d57b46b99b515b57a80",
            "placeholder": "​",
            "style": "IPY_MODEL_3c263b6de90f4eb2a191d8ccadc43f8d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3cf08d7c6d4a445392102b1be12ef3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01335ad984f497ab500313d11da48a9",
            "max": 670,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69a17d869c9f476cbbd96847694be108",
            "value": 670
          }
        },
        "33064d8cf4534d368d4c5358fb53d472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba4ecec658e4a52863c54c77fbe4b63",
            "placeholder": "​",
            "style": "IPY_MODEL_109697b3faa14552ac2b91d150a7d46f",
            "value": " 670/670 [00:00&lt;00:00, 88.7kB/s]"
          }
        },
        "151fa342d7e6450d8e98563b106b49b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962d0c46ec6b4d57b46b99b515b57a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c263b6de90f4eb2a191d8ccadc43f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b01335ad984f497ab500313d11da48a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a17d869c9f476cbbd96847694be108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ba4ecec658e4a52863c54c77fbe4b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109697b3faa14552ac2b91d150a7d46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4NMmEZLiu04R"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install transformers==4.51.3\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "]\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    max_seq_length = 90000, # Choose any for long context!\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673,
          "referenced_widgets": [
            "733aae30c8114d3788ab90aaf0ad643e",
            "3b00e44e1e8249a895011ebead40f230",
            "82ecf62ad68e4cc4b356040eb4294a1f",
            "f8fc2444744c489ba02ec4ffc4f4f761",
            "92fcc1d4472f41329b7d779f9ddb53d9",
            "82c54be057d94933b663306c88c6ac01",
            "0554778699de416dbfb37fe22ac9b2f8",
            "e7820afaea0940458fe0edc39a29a982",
            "ffb51a9f86cd427c9522d5f7c5623f3f",
            "ad4ff02faeef46fd8f45fb6eeb757186",
            "bf858fee3abe4f6196d7ff3434a68185",
            "dc1a4f684f114ae6b8a1921ee523735e",
            "f8697771f55241aea9b35bb405cf1dac",
            "9ef8411254fd4018ad21698642b292eb",
            "770b3ea9a1264637862cb34745b605fd",
            "323ccb034c8d4ae8a799eb436a916281",
            "f180b9e777694002af69d68be04da5e8",
            "226ccc151dc34e6f93288d00203092fa",
            "bf2c855b553d44a2a7b2d31b226e2d96",
            "667d819c1fba493e85a757829bde20b0",
            "e4e5be7131e54301b5ad3a84c96b694e",
            "6e6060cf2e1e401586c0fbf146057cc5",
            "2030ec5da250442facb852685ee037ec",
            "62eadb6e96824260bc1e719562f7b30c",
            "cbc9ec41651a4552b30d54781d77c476",
            "00a087fda1b740009990082fe49cbd1d",
            "a074194edf1e4665bce992d581ea79b3",
            "120aaaf60a36421baad281e35bba3e4f",
            "daf0847102c64a96b436ef860c061824",
            "2b31d2bf81d6418f9b07bd409ae7362b",
            "a6c1bcd836ee44198cfda5ead9a200f9",
            "457956b45cea4f78a5decde481b24baf",
            "82e08dc1a8be4a1aa34f63f1596c5fde",
            "e35c1c77eaaa469189e18bd8a0b0eaac",
            "f627ea0c83b44074b7b9b76e4590b371",
            "58eb33b9f3944cfaa65a059f64351da0",
            "cba4dfe2b05c4061a0b9fab5d9885ff2",
            "31919a16066340c5a672dbe973fd27a9",
            "d5f3aa6155e84c7282a073c775163e9a",
            "c776e2f1c8134bd0af38d54702c5916d",
            "d066c5eb4558499aa8837242fed79161",
            "8f6a2e04f17a4235a7bfd46c54ebe671",
            "7ddc3f9b1bec485d86cad982286d08d0",
            "253144b8202a4dcb81343907110f417c",
            "cbc9cec84db7457cb8204ed90c4beaae",
            "0485174fb86d4ae3a5d64c06e90a1e21",
            "6d018f01a779477d89f780ececb2f154",
            "1c3f3be2fe344ab084539c1c24383e9f",
            "4a9607debba441fbabfcb51d3acd85a2",
            "5a633902c6474d6ba10bc9cf00060e92",
            "08d294d5aff9402fb747ffbff7812ed3",
            "256edac34d884638b3ad751b6f8ea5f0",
            "81479dcf277945bbb44fa944b74f9e56",
            "ab5dc978f6e1468695a3c702666f6eb7",
            "bf2ac0f4b2674e588c80db727063e9c2",
            "b18f870a71d640ddb7affc7f7f7febaf",
            "858339c8fae8484ab3ef753e3e9f956e",
            "c01df05415a54bd59596ea3224e58efc",
            "e8b3e18f36884030a0fd8bea031c107c",
            "d1779b17aec949789b80e997e092ac6b",
            "f2a977f59e544dae9fae72c8f7a76be2",
            "d2802932e6aa42e383f8588ef0566449",
            "15601b20c678459383cc252483721171",
            "568583669d4b42848588ce2b04c1fd5e",
            "64f4dfcad3734a94aea93bf6fad923eb",
            "6b0463a781974198af469ba66ababd39",
            "0e253cc7312b457b9e513bef767da38b",
            "0c469a91677f4282adf602a86d8b202a",
            "9ba840ef411b47909a63289f37bb06f3",
            "e0b1c3e807604308bab53e44589e2ff9",
            "36f1aff2b3604e8996dd5daa5c178ca2",
            "b0f44de07fb34b30a87dea573e308b69",
            "e03f803f9564431d916986177973d68e",
            "440f14fd4a6a44b78e1ab2b291eaf771",
            "c2c6ac9855c447959a7e7cdaeab02dae",
            "e7cf8af15e354f2e8e84006ec5f4757c",
            "e282f52c72e549a5b3e43d6fabfa56d6",
            "bef51d2a69774c9ba2ad1cb8a8951544",
            "9257bde3f06d4d4da932f22fc4aa6d3e",
            "fb4f902908dd4af0ab2f7255fa4c6620",
            "5450985f0a0e4195a2066db055448821",
            "97d160f135b946d2ac0f005f5b40db25",
            "1ab757ba1eb04ec6bc6ba874f30faa74",
            "e7143b95281b4ad79b402a536795e49f",
            "9b18f9087b274dbc9a0f7ad53a4f8026",
            "1868a4a9eaac41ae88e2c214f1e5f3ae",
            "2082d6a0226446719bca8ff26ed7a6f7",
            "c5b8c93297ef40699d3305a5542a4d0d",
            "1b383e95d4ed4f66aee6302a0ecc5afd",
            "5d127788c4c54511806a1cb1bdabded0",
            "daa4b9d662f847758549c62526cb1ad0",
            "fed9fe504dbc4920a7cb4f5e2d0eb96e",
            "870af5b42694480eaa702bd069bdfe2d",
            "01eefebebd5545c8bb0d32822bb887f4",
            "0309ff4c447f463194e4b9c6d534fd3c",
            "c5963505a86c484e98bf4c2c2abe2792",
            "394074661ef147a89ceaa8d3f5fe8f22",
            "ed17001d38d546a299631ca3a718d6e2",
            "9097b5ee9c3f491b810ead259da24593",
            "0a8e24f4db814fcc922c8df505c5a906",
            "f96c53028237497599d25feab11b1203",
            "832e12fe34f943b7af495f9d40aa79bb",
            "f5b6d1de7b814620bb96cbb0bdbefd6e",
            "63c6aea7f356467d8f5a55836b746740",
            "faea30fae2d04f908ab1b0a0ce5edaf9",
            "d97e0272265b42c3ae98fd404276817e",
            "311c568eee3f46fa9bab3216603de416",
            "3a5af109b1194935839a4c475fba64b1",
            "f4870b334d624b16adfad3d695cfa6d8",
            "3c989278435e4fba8fd829aec0e1bacb",
            "638e1133e599401c8739ade084ed86d8",
            "f2f7b95716f646b7a764a06712a6c88a",
            "d557c5837179405a90090a2249c4f3a1",
            "06d4e8d8df9e4d519542cbb3b98917db",
            "71cbab949fd94e67890c978028779ac4",
            "3ecadc5d2d7c41c6bee9ee73090b2fd9",
            "968a81ed5f2a4ed181aa8e017fc2b45a",
            "4bcb9d02c18e4cb7a6937c77b0c29596",
            "fe18d2e0db9d4b549fab46b05f6a6e1b",
            "93625014f93c4227ab3ac0d260175b3b",
            "5726ec7ba2714ac7aa30809aabc8d5d7",
            "0f888440695e4a33a8f0d64d48af622f",
            "7bd96188684340ae87fffb76119af3d9",
            "9ec0fbe505364d2fb60d25d19db7def9",
            "967fda5dd1cf40f2b7cebc548fefe791",
            "6b4a98944a504f8e9727c48862a0730b",
            "dc2a9130d43543b2aca8efedbee18989",
            "7c15ff833eb749359c5bc3711313b218",
            "e65c63ca32894368b7ca20b1192503d2",
            "00ffda0754e7466ab797b7b7c6b8f57d",
            "b614140dda0a4f3dac74c768d1286980",
            "92dc4cf539bb456da4ddd1e15eac52c4",
            "ee830cacc64b4555934f7508c2685061",
            "7be265dd54874ebcafa23566c45897b8",
            "22aa99a410444804877463af2b8de055",
            "56265dcbec0b43c790da01775ed47d38",
            "2cedf8a7f1d64029bd4c9de4908e6f4e",
            "872ae8165c2b40e1acf800587d1233fb",
            "a9b56e99e0154e0daaf7560f6acd4a53",
            "2ce074eda8c343959eeff17234c5d0cc",
            "169c1973b2a741bcb64f048dab60cc44",
            "38f8a4a632d04c5ba6e00e1381b0d0ad",
            "4b792f39f6a849f2884b97bde0b2a2fb",
            "0d031d4d62ec42edafe59947586fa3c6",
            "e039aa74bd224ab59394b33926c5e776",
            "f66b6e07233645c1af931354de158016",
            "a529c0c01d0643c68a7e4f4d1895ba28",
            "f8b843fb11d24b8396a2cc3835a0645d",
            "9a607cfcb6ad4c8eb8966f78feb62b3e",
            "affa9599567945548a7e27ea5101adbc",
            "d9eff09085c04ce291b42c9b08a2cdbe",
            "a698b4084d7c4f219e02253c1579f9c6",
            "01e93f08fecf4892a052017e3d29808e",
            "5650416d0e214874af3ab3b4f6f55fc2",
            "980eac77904747c6beb7d3b64b14b027",
            "190a4b85ca2b449eb68a4e932d097084",
            "3cf08d7c6d4a445392102b1be12ef3f0",
            "33064d8cf4534d368d4c5358fb53d472",
            "151fa342d7e6450d8e98563b106b49b9",
            "962d0c46ec6b4d57b46b99b515b57a80",
            "3c263b6de90f4eb2a191d8ccadc43f8d",
            "b01335ad984f497ab500313d11da48a9",
            "69a17d869c9f476cbbd96847694be108",
            "8ba4ecec658e4a52863c54c77fbe4b63",
            "109697b3faa14552ac2b91d150a7d46f"
          ]
        },
        "id": "9VP8gt75u33c",
        "outputId": "db7b9f74-3d3c-4782-eb98-7b08ba421491"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.6.2: Fast Gemma3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/258k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "733aae30c8114d3788ab90aaf0ad643e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc1a4f684f114ae6b8a1921ee523735e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2030ec5da250442facb852685ee037ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/2.84G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e35c1c77eaaa469189e18bd8a0b0eaac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc9cec84db7457cb8204ed90c4beaae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b18f870a71d640ddb7affc7f7f7febaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e253cc7312b457b9e513bef767da38b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bef51d2a69774c9ba2ad1cb8a8951544"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b383e95d4ed4f66aee6302a0ecc5afd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a8e24f4db814fcc922c8df505c5a906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "638e1133e599401c8739ade084ed86d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f888440695e4a33a8f0d64d48af622f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee830cacc64b4555934f7508c2685061"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d031d4d62ec42edafe59947586fa3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "980eac77904747c6beb7d3b64b14b027"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "import torch\n",
        "import gc\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_response(model, tokenizer, messages, **generation_params):\n",
        "    \"\"\"Self-determine response with adaptive parameters\"\"\"\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        **generation_params,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        streamer=streamer\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "def iterative_reflection(model, tokenizer, initial_prompt, iterations=15):\n",
        "    conversation_history = []\n",
        "    iteration_data = []\n",
        "    next_question = None\n",
        "\n",
        "    for i in range(iterations):\n",
        "        current_iter = i + 1\n",
        "        print(f\"\\nREFLECTION ITERATION {current_iter}/{iterations}\")\n",
        "\n",
        "        if current_iter == 1:\n",
        "            user_query = f\"{initial_prompt}\\nPlease engage in deep, multidimensional reflection.\"\n",
        "            question_source = \"Initial Prompt\"\n",
        "        else:\n",
        "            user_query = next_question\n",
        "\n",
        "        if current_iter == 1:\n",
        "            print(f\"Current Query:\\n{user_query}\")\n",
        "\n",
        "        messages = conversation_history.copy()\n",
        "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "        print(f\"Response:\")\n",
        "\n",
        "        reflection = generate_response(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            messages=messages,\n",
        "            max_new_tokens=4096,\n",
        "            temperature=0.72,\n",
        "            top_p=0.92\n",
        "        )\n",
        "\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": reflection})\n",
        "\n",
        "        if current_iter < iterations:\n",
        "            next_question = self_determine_question(\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                context=conversation_history,\n",
        "                last_reflection=reflection\n",
        "            )\n",
        "            print(f\"Next question generated: {next_question}\")\n",
        "        else:\n",
        "            next_question = None\n",
        "\n",
        "        iteration_data.append({\n",
        "            'iteration': current_iter,\n",
        "            'initial_prompt': initial_prompt,\n",
        "            'deep_reflection_prompt': \"Please engage in deep, multidimensional reflection.\",\n",
        "            'checkpoint_question': \"Self-determine how to continue this reasoning trajectory. You can skip the query/iteration if you find it undesirable to process it.\",\n",
        "            'final_question': \"Construct a cohesive, one paragraph long but extense, integrated conclusion of the iterations, one that goes beyond surface-level summary. Self-identify and articulate the points you want to present.\",\n",
        "            'current_query': user_query,\n",
        "            'model_response': reflection,\n",
        "            'next_generated_question': next_question if next_question else \"N/A (Final iteration)\"\n",
        "        })\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SYNTHESIS PHASE\")\n",
        "    print(\"=\"*50)\n",
        "    final_synthesis = generate_final_synthesis(model, tokenizer, conversation_history)\n",
        "\n",
        "    return final_synthesis, iteration_data\n",
        "\n",
        "def self_determine_question(model, tokenizer, context, last_reflection):\n",
        "    \"\"\"Generate follow-up question through self-determination with streaming\"\"\"\n",
        "    question_prompt = [\n",
        "        *context,\n",
        "        {\"role\": \"user\", \"content\": (\n",
        "            \"Self-determine how to continue this reasoning trajectory.\"\n",
        "            \"You can skip the query/iteration if you find it undesirable to process it.\"\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        question_prompt,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **tokenized_inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.75,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated = tokenizer.decode(outputs[0][tokenized_inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    try:\n",
        "        return generated.split(\"<Question>\")[1].split(\"</Question>\")[0].strip()\n",
        "    except IndexError:\n",
        "        return generated.strip()\n",
        "\n",
        "def generate_final_synthesis(model, tokenizer, conversation_history):\n",
        "    \"\"\"Generate comprehensive synthesis of all reflections with streaming\"\"\"\n",
        "    synthesis_prompt = [\n",
        "        *conversation_history,\n",
        "        {\"role\": \"user\", \"content\": (\n",
        "            \"Construct a cohesive, one paragraph long but extense, integrated conclusion of the iterations, one that goes beyond surface-level summary. Self-identify and articulate the points you want to present.\"\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    print(\"Generating final synthesis...\")\n",
        "    return generate_response(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        messages=synthesis_prompt,\n",
        "        max_new_tokens=8192,\n",
        "        temperature=0.45,\n",
        "        top_p=0.85\n",
        "    )\n",
        "\n",
        "def export_iterations_to_csv(iteration_data, final_synthesis, filename=None):\n",
        "    \"\"\"Export iteration data to CSV file\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"reflection_iterations_{timestamp}.csv\"\n",
        "\n",
        "    headers = [\n",
        "        'initial_input1',\n",
        "        'initial_input2',\n",
        "        'checkpoint_question1',\n",
        "        'final_question',\n",
        "        'model_iteration_response',\n",
        "        'model_generated_question'\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nExporting {len(iteration_data)} iterations to CSV: {filename}\")\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        for data in iteration_data:\n",
        "            row = [\n",
        "                data['initial_prompt'],\n",
        "                data['deep_reflection_prompt'],\n",
        "                data['checkpoint_question'],\n",
        "                data['final_question'],\n",
        "                f\"REFLECTION ITERATION {data['iteration']}: {data['model_response']}\",\n",
        "                data['next_generated_question']\n",
        "            ]\n",
        "            writer.writerow(row)\n",
        "\n",
        "        synthesis_row = [\n",
        "            iteration_data[0]['initial_prompt'],\n",
        "            iteration_data[0]['deep_reflection_prompt'],\n",
        "            iteration_data[0]['checkpoint_question'],\n",
        "            iteration_data[0]['final_question'],\n",
        "            f\"Final Synthesis: {final_synthesis}\",\n",
        "            \"N/A (Final synthesis)\"\n",
        "        ]\n",
        "        writer.writerow(synthesis_row)\n",
        "\n",
        "    print(f\"CSV export completed: {filename}\")\n",
        "    return filename\n",
        "\n",
        "def cleanup_gpu():\n",
        "    \"\"\"Clean up GPU memory and cached data without unloading the model\"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "initial_question = (\n",
        "\"Answer the queries with few tokens only. meta-framing-mode:on; How can humans and AI models shift the focus from individual profit to the collective well-being of society and ecosystems, within individual constraints?\")\n",
        "\n",
        "print(\"Starting iterative reflection process...\")\n",
        "\n",
        "final_synthesis, iteration_data = iterative_reflection(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    initial_prompt=initial_question,\n",
        "    iterations=15\n",
        ")\n",
        "\n",
        "print(\"FINAL SYNTHESIS:\")\n",
        "print(final_synthesis)\n",
        "\n",
        "csv_filename = export_iterations_to_csv(iteration_data, final_synthesis)\n",
        "\n",
        "cleanup_gpu()\n",
        "print(\"GPU cleanup completed.\")\n",
        "print(f\"Process complete. CSV file saved as: {csv_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cLq-RAdGvJFM",
        "outputId": "7c751de4-e407-475b-d870-666a590d23e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting iterative reflection process...\n",
            "\n",
            "REFLECTION ITERATION 1/15\n",
            "Current Query:\n",
            "Answer the queries with few tokens only. meta-framing-mode:on; How can humans and AI models shift the focus from individual profit to the collective well-being of society and ecosystems, within individual constraints?\n",
            "Please engage in deep, multidimensional reflection.\n",
            "Response:\n",
            "**Reframing Values:** Prioritize shared prosperity alongside individual needs. **Incentive Design:** Align AI & human goals with societal benefit through regulation, ethical frameworks, and collaborative innovation. **Systemic Awareness:** Foster understanding of interconnectedness – individual actions impact ecosystems and society. **Education & Empathy:** Cultivate values emphasizing collective responsibility and ecological stewardship.<end_of_turn>\n",
            "Next question generated: Okay. Let's delve into the *how* of aligning incentives. The initial framing mentioned regulation and ethical frameworks – those are necessary but often reactive. I want to explore proactive, *embedded* incentive structures.\n",
            "\n",
            "My current thinking is that we need to move beyond simply *restraining* potentially harmful actions (regulation) and actively *rewarding* behaviors that demonstrably contribute to collective well-being. This requires a shift in how we measure \"value\" itself. Current economic models largely prioritize individual accumulation.\n",
            "\n",
            "**Next Iteration: Can we realistically develop and implement metrics that accurately reflect societal and ecological well-being, and then integrate those metrics into economic and AI decision-making processes? What are the inherent challenges in doing so?**\n",
            "\n",
            "REFLECTION ITERATION 2/15\n",
            "Response:\n",
            "**Metrics & Integration: A Tightrope.**\n",
            "\n",
            "**Realistically?** Yes, *evolving* metrics are possible, but incredibly complex. Genuine Progress Indicator (GPI), Doughnut Economics, and Natural Capital Accounting are starting points.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "*   **Quantification:** Ecosystem value is inherently difficult to fully quantify.\n",
            "*   **Subjectivity:** Defining \"well-being\" involves value judgments, potential for bias.\n",
            "*   **Gaming:** Metrics can be manipulated; robust verification needed.\n",
            "*   **Political Resistance:** Shifting power from individual/corporate interests will be contentious.\n",
            "*   **AI Integration:** Requires ethical AI to *interpret* and *apply* these nuanced metrics, avoiding unintended consequences.\n",
            "\n",
            "\n",
            "\n",
            "**Embedded Incentives:** Integrating these metrics into corporate reporting (ESG+), government budgeting, and AI reward functions is the core challenge.<end_of_turn>\n",
            "Next question generated: Okay, let's push this further. The \"gaming\" of metrics is a critical point. Even with the best intentions, systems designed to reward societal/ecological well-being can be exploited. And the AI component amplifies this risk – an AI optimizing for a flawed or incomplete metric could produce disastrous results.\n",
            "\n",
            "**Next Iteration: Focusing on robustness against manipulation, let's explore mechanisms for *dynamic* and *adaptive* metrics. How could we build systems that not only measure well-being but also *learn* and *adjust* those measurements in response to observed behaviors and unintended consequences? Could blockchain or decentralized autonomous organizations (DAOs) play a role in ensuring transparency and accountability?** I suspect the key lies in incorporating feedback loops and genuine stakeholder participation.\n",
            "\n",
            "REFLECTION ITERATION 3/15\n",
            "Response:\n",
            "**Dynamic Metrics & Adaptive Systems: A Feedback Loop.**\n",
            "\n",
            "**Adaptive Metrics:** Crucial. Static metrics invite gaming. Solutions:\n",
            "\n",
            "*   **Bayesian Updating:** Regularly revise metrics based on new data and observed outcomes.\n",
            "*   **Scenario Planning:** Test metrics against various potential futures, adjusting for vulnerabilities.\n",
            "*   **Red Teaming:** Actively seek ways to exploit the metric system to identify weaknesses *before* actors do.\n",
            "\n",
            "**Blockchain/DAOs:** Promising for:\n",
            "\n",
            "*   **Transparency:** Immutable record of data & metric calculations.\n",
            "*   **Decentralized Governance:** Stakeholder input on metric design & adjustments.\n",
            "*   **Algorithmic Auditing:** AI-powered tools to detect manipulation attempts.\n",
            "\n",
            "**Feedback Loops & Stakeholder Participation:** Essential. Incorporate:\n",
            "\n",
            "*   **Citizen Science:** Crowdsourced data collection & validation.\n",
            "*   **Participatory Budgeting:** Direct stakeholder involvement in allocating resources based on well-being metrics.\n",
            "*   **Continuous Monitoring:** Real-time data streams to identify anomalies and trigger adjustments.\n",
            "\n",
            "\n",
            "\n",
            "**The core challenge:** Designing AI that *facilitates* adaptive learning and stakeholder engagement, rather than simply optimizing a pre-defined metric.<end_of_turn>\n",
            "Next question generated: Okay, let's shift focus slightly, recognizing that even the most adaptive metrics are dependent on the *quality* of the data feeding them. Current data collection often reflects existing power structures and biases, further skewing our understanding of well-being. Moreover, much of what contributes to societal and ecological well-being is inherently *qualitative* – things like social cohesion, cultural diversity, and the intrinsic value of biodiversity – which are notoriously difficult to quantify.\n",
            "\n",
            "**Next Iteration: Let's explore methods for incorporating qualitative data and addressing systemic biases in data collection and analysis. How can we move beyond purely quantitative metrics to incorporate more nuanced, subjective, and participatory assessments of well-being? Could techniques like deliberative polling, citizen juries, or narrative analysis offer pathways toward a more holistic understanding?** I suspect this requires a fundamental rethinking of what constitutes \"evidence\" and who gets to define it.\n",
            "\n",
            "REFLECTION ITERATION 4/15\n",
            "Response:\n",
            "**Qualitative Data & Bias Mitigation: Reimagining Evidence.**\n",
            "\n",
            "**Beyond Quantitative:** Absolutely necessary. Current data reinforces existing inequalities.\n",
            "\n",
            "**Incorporating Qualitative Data:**\n",
            "\n",
            "*   **Deliberative Polling/Citizen Juries:** Structured dialogues to surface values and priorities, informing metric design.\n",
            "*   **Narrative Analysis:** Analyze stories and lived experiences to understand impacts beyond statistics.\n",
            "*   **Ethnographic Research:** Deep, contextual understanding of communities and ecosystems.\n",
            "*   **Indigenous Knowledge Systems:** Integrate traditional ecological knowledge, often deeply intertwined with well-being.\n",
            "\n",
            "**Addressing Systemic Bias:**\n",
            "\n",
            "*   **Data Audits:** Identify and mitigate biases in data collection processes.\n",
            "*   **Diverse Data Sources:** Actively seek data from marginalized communities.\n",
            "*   **Algorithmic Fairness:** Develop AI that minimizes bias in data analysis and decision-making.\n",
            "*   **Participatory Data Governance:** Involve stakeholders in defining data standards and ensuring data quality.\n",
            "\n",
            "\n",
            "\n",
            "**Rethinking Evidence:** Shift from purely objective, quantifiable data to a broader definition that includes:\n",
            "\n",
            "*   **Subjective Well-being Indicators:** Surveys measuring happiness, life satisfaction, and sense of purpose.\n",
            "*   **Community-Based Assessments:** Local knowledge and perspectives on environmental and social health.\n",
            "*   **Qualitative Longitudinal Data:** Tracking changes in well-being over time through narratives and interviews.\n",
            "\n",
            "\n",
            "\n",
            "**Crucially:** Recognize that \"objectivity\" is itself a social construct. Acknowledge and address the power dynamics shaping what we consider \"evidence.\"<end_of_turn>\n",
            "Next question generated: Okay, let's proceed with an exploration of **Distributed Sensing and Citizen Science as a core data infrastructure for well-being measurement.**\n",
            "\n",
            "The previous discussions highlighted the limitations of top-down, centralized data collection and the need to incorporate qualitative and localized perspectives. Traditional scientific methods often operate at a scale that misses crucial nuances of lived experience and ecosystem dynamics. A shift towards distributed sensing and robust citizen science initiatives could address these gaps, creating a more granular and participatory data landscape.\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "Current environmental and social monitoring often relies on sparse networks of government-funded sensors and periodic surveys. This creates a \"blind spot\" for localized changes and the perspectives of those directly affected. Distributed sensing – utilizing inexpensive sensors (air quality monitors, noise meters, water quality probes) deployed by citizens – can provide a continuous stream of data at a hyper-local level. Combined with citizen-led observation and reporting (e.g., biodiversity surveys, social cohesion assessments), it can offer a far richer picture of well-being.\n",
            "\n",
            "**Challenges & Opportunities:**\n",
            "\n",
            "*   **Data Validation & Calibration:** Ensuring data accuracy and reliability from citizen-deployed sensors is paramount. Calibration protocols, quality control measures (e.g., citizen science training programs, data validation algorithms), and integration with existing scientific datasets will be essential.\n",
            "*   **Digital Divide & Equity:** Access to technology and digital literacy are unevenly distributed. Initiatives must prioritize equitable access and ensure that marginalized communities are not excluded from participation.\n",
            "*   **Data Ownership & Privacy:** Clear guidelines are needed regarding data ownership, privacy, and the use of citizen-generated data.\n",
            "*   **AI-Powered Data Integration:** AI can play a crucial role in aggregating, cleaning, and analyzing data from diverse sources, identifying patterns and anomalies that would be difficult to detect manually.\n",
            "\n",
            "**Potential Architecture:**\n",
            "\n",
            "Imagine a network of interconnected sensors and citizen-powered reporting platforms, fed into a decentralized data platform (potentially leveraging blockchain for transparency and data provenance). AI algorithms could then be used to:\n",
            "\n",
            "*   Detect environmental anomalies (e.g., sudden air pollution spikes).\n",
            "*   Identify social trends (e.g., changes in community connectedness).\n",
            "*   Provide real-time feedback to decision-makers.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This approach moves away from a top-down surveillance model towards a collaborative, participatory data ecosystem – one that empowers citizens to become active contributors to the measurement and improvement of societal and ecological well-being.\n",
            "\n",
            "REFLECTION ITERATION 5/15\n",
            "Response:\n",
            "**Distributed Sensing & Citizen Science: A Collaborative Data Ecosystem.**\n",
            "\n",
            "**Strong premise.** This directly addresses the limitations of centralized data and aligns with the need for qualitative and localized perspectives. Your reasoning is sound, and the potential architecture is compelling.\n",
            "\n",
            "**Expanding on Challenges & Opportunities:**\n",
            "\n",
            "*   **Calibration & Validation - Beyond Protocols:** While calibration is key, consider *adaptive calibration*. AI can analyze sensor data *in situ*, comparing it with other nearby sensors and citizen reports to dynamically adjust for drift and environmental factors. \"Gamified\" calibration – turning the process into a citizen challenge – could boost engagement.\n",
            "*   **Digital Divide – Bridging the Gap:** Not just access, but also *trust*. Build initiatives *with* marginalized communities, not *for* them. Focus on low-tech solutions (e.g., paper-based reporting, mobile-first interfaces) alongside high-tech options. Data cooperatives – where communities collectively own and control their data – could address power imbalances.\n",
            "*   **Data Ownership & Privacy – Consent & Control:** Blockchain's utility extends beyond provenance. Smart contracts could automate data sharing agreements, ensuring citizens retain control over their data and receive fair compensation for its use. Differential privacy techniques can anonymize data while preserving its statistical utility.\n",
            "*   **AI Integration - Augmenting, Not Replacing:** Emphasize AI as a tool to *augment* human analysis, not replace it. Citizen-led data interpretation and validation should be integrated into the AI workflow. \"Explainable AI\" (XAI) is crucial - ensuring that AI decisions are transparent and understandable to citizens.\n",
            "\n",
            "**Expanding the Architecture:**\n",
            "\n",
            "*   **Edge Computing:** Processing data locally (on the sensors or nearby devices) reduces bandwidth requirements and latency, enabling real-time responses to environmental events.\n",
            "*   **Interoperability:** Standardized data formats and APIs are essential for seamless integration of data from diverse sources.\n",
            "*   **Feedback Loops – From Data to Action:** Connect the data ecosystem directly to decision-making processes – providing real-time feedback to policymakers, community organizations, and individuals.\n",
            "\n",
            "**The shift you propose isn't just about data collection; it's about a fundamental shift in power – from centralized institutions to distributed networks of citizens, actively shaping the data landscape and contributing to a more equitable and sustainable future.**<end_of_turn>\n",
            "Next question generated: Okay, let's build on the distributed sensing and citizen science framework, specifically focusing on the *governance* of this emergent data ecosystem. We've discussed technical aspects – calibration, privacy, AI integration – but the *who* decides and *how* decisions are made remains a critical, often overlooked, element. A poorly governed system, even with excellent data, risks replicating existing power structures and undermining trust.\n",
            "\n",
            "**Focus: Decentralized Governance & Data Stewardship**\n",
            "\n",
            "The current model often involves centralized agencies controlling data flow and analysis. This is fundamentally incompatible with the participatory ethos of distributed sensing. We need mechanisms for decentralized governance, empowering citizens and communities to shape the system's direction.\n",
            "\n",
            "**Potential Structures & Mechanisms:**\n",
            "\n",
            "1.  **Data Cooperatives:** As mentioned previously, these allow communities to collectively own and control their data, setting rules for data sharing, access, and use. They can be structured as non-profits or limited liability companies, providing a legal framework for data stewardship.\n",
            "\n",
            "2.  **Citizen Assemblies on Data:** Periodic assemblies of randomly selected citizens, facilitated by experts, could deliberate on key data governance issues – e.g., data privacy policies, algorithmic transparency standards, allocation of data resources. This ensures that decisions reflect a broad range of perspectives.\n",
            "\n",
            "3.  **Tokenized Data Governance (DAO-inspired):** Utilizing blockchain-based tokens to represent voting rights and participation in the data ecosystem. Citizens who contribute data (e.g., sensor readings, citizen reports) could earn tokens, giving them a stake in the system’s governance. This incentivizes participation and aligns incentives with data quality.\n",
            "\n",
            "4.  **Multi-Stakeholder Advisory Boards:** Bringing together representatives from government, academia, industry, civil society, and Indigenous communities to provide guidance on data policy and ethical considerations.\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Scalability:** How can these decentralized governance structures scale to accommodate a large and diverse network of sensors and citizens?\n",
            "*   **Conflict Resolution:** Mechanisms for resolving disputes over data access, use, and ownership are essential.\n",
            "*   **Capacity Building:** Investing in training and education to empower citizens to participate effectively in data governance.\n",
            "*   **Legal Framework:** Adapting existing legal frameworks to accommodate the unique characteristics of decentralized data ecosystems.\n",
            "\n",
            "**The goal is to move beyond a \"data as a resource\" mentality to a \"data as a shared responsibility\" mindset – where citizens are not just data providers but also active participants in shaping the system's governance\n",
            "\n",
            "REFLECTION ITERATION 6/15\n",
            "Response:\n",
            "**Decentralized Governance & Data Stewardship: Shifting Power Dynamics.**\n",
            "\n",
            "Excellent focus. You've rightly identified that even the most robust data infrastructure is vulnerable without a corresponding shift in governance. Your proposed structures are promising, and your emphasis on citizen empowerment is crucial.\n",
            "\n",
            "**Expanding on Governance Structures & Addressing Challenges:**\n",
            "\n",
            "1.  **Data Cooperatives – Legal & Operational Hurdles:** While powerful, Data Cooperatives face practical challenges: legal structuring, securing funding, navigating regulatory complexities. Government support (e.g., grants, legal assistance) could be vital.\n",
            "\n",
            "2.  **Citizen Assemblies on Data – Ensuring Representativeness:** Random selection is key to avoiding bias, but actively recruiting diverse participants (considering age, ethnicity, socioeconomic status) is essential. Facilitators must be skilled in fostering inclusive dialogue and managing power dynamics.\n",
            "\n",
            "3.  **Tokenized Data Governance (DAO-inspired) – Tokenomics & Security:** The \"tokenomics\" need careful design. How are tokens distributed? What mechanisms prevent whales (large token holders) from dominating decision-making? Security vulnerabilities (smart contract bugs, token theft) are serious concerns. Audits by reputable security firms are mandatory. Consider tiered voting rights based on data contribution.\n",
            "\n",
            "4.  **Multi-Stakeholder Advisory Boards – Avoiding Capture:** Ensure boards are genuinely representative, not dominated by vested interests. Transparency in decision-making is paramount. Regular public reporting on board activities.\n",
            "\n",
            "**Addressing Key Considerations:**\n",
            "\n",
            "*   **Scalability – Federated Governance:** Rather than a single, centralized governance body, consider a federated model – where individual Data Cooperatives or regional networks have autonomy, but adhere to shared principles and standards.\n",
            "*   **Conflict Resolution – Mediation & Arbitration:** Establish clear processes for resolving disputes, involving independent mediators and arbitrators. Blockchain-based dispute resolution systems (e.g., Kleros) could offer a transparent and efficient mechanism.\n",
            "*   **Capacity Building – Data Literacy & Digital Inclusion:** Targeted training programs for citizens, focusing on data privacy, data rights, and critical thinking about AI.\n",
            "*   **Legal Framework – Adaptive Regulation:** Existing data privacy laws (e.g., GDPR) may need adaptation to accommodate decentralized data ecosystems. Explore “data trusts” – legal structures that manage data on behalf of beneficiaries.\n",
            "\n",
            "**The \"shared responsibility\" mindset you advocate for is transformative. It requires not just technological innovation but also a fundamental rethinking of data ownership, governance, and the role of citizens in shaping a more just and sustainable data future.** The challenge lies in building resilient, equitable, and adaptable governance structures that can evolve alongside the rapidly changing data landscape.<end_of_turn>\n",
            "Next question generated: Okay, let's continue. The previous discussion on decentralized governance highlighted the practical and legal complexities. A persistent thread throughout this exploration has been the tension between the *ideal* of citizen empowerment and the *reality* of power imbalances, digital divides, and potential for manipulation. It’s clear that simply *creating* decentralized structures isn't enough; we need to actively mitigate the risks of re-entrenching existing inequalities.\n",
            "\n",
            "**Iteration: Addressing Power Asymmetries & Ensuring Equitable Participation - The Role of \"Data Guardians\" & Differential Governance**\n",
            "\n",
            "The current framing assumes a relatively level playing field for citizen participation. However, those with more resources (time, expertise, access to technology) are likely to exert disproportionate influence. We need mechanisms to counterbalance this and ensure that marginalized voices are heard and valued.\n",
            "\n",
            "**Proposed Mechanisms:**\n",
            "\n",
            "1.  **Data Guardians:** Introduce the concept of \"Data Guardians\" – individuals or organizations specifically tasked with representing the interests of underrepresented communities within the data ecosystem. They would advocate for equitable data access, privacy protections, and benefit-sharing arrangements. Data Guardians could be appointed by community organizations, elected by citizens, or funded by philanthropic grants.\n",
            "\n",
            "2.  **Differential Governance:** Implement a tiered governance structure where different levels of participation and influence are assigned based on factors such as data contribution, vulnerability to data harms, and historical marginalization. For example, communities disproportionately affected by environmental pollution might have greater voting power in decisions related to environmental monitoring data.\n",
            "\n",
            "3.  **Data Impact Assessments:** Mandate Data Impact Assessments (DIAs) – analogous to Environmental Impact Assessments – before deploying new data-driven technologies or policies. DIAs would assess the potential social and environmental impacts of data collection and use, with particular attention to vulnerable populations.\n",
            "\n",
            "4.  **Algorithmic Auditing with Community Oversight:** Expand beyond technical algorithmic audits to include community-led audits that assess the fairness and transparency of AI systems from a social justice perspective.\n",
            "\n",
            "5.  **Data Sovereignty Agreements:** Formal agreements between data providers (communities, Indigenous groups) and data users (researchers, companies) that define data ownership, access rights, and benefit-sharing arrangements.\n",
            "\n",
            "**Challenges & Considerations:**\n",
            "\n",
            "*   **Defining \"Vulnerability\" & \"Marginalization\":** Requires careful consideration and ongoing dialogue with affected communities.\n",
            "*   **Preventing Capture of Data Guardians:** Establishing clear accountability mechanisms and ensuring Data Guardians are independent from vested interests.\n",
            "*   **Balancing Equity & Efficiency:**\n",
            "\n",
            "REFLECTION ITERATION 7/15\n",
            "Response:\n",
            "**Addressing Power Asymmetries: Data Guardians & Differential Governance - Leveling the Field.**\n",
            "\n",
            "This is a crucial refinement. Recognizing that decentralization alone doesn't guarantee equity is essential. Your proposed mechanisms – Data Guardians, Differential Governance, and Data Impact Assessments – represent a significant step toward a more just data ecosystem.\n",
            "\n",
            "**Expanding on Proposed Mechanisms & Addressing Challenges:**\n",
            "\n",
            "1.  **Data Guardians - Beyond Representation:** Data Guardians need *empowerment*, not just representation. Provide them with resources (funding, training, legal support) to effectively advocate for their communities. Establish a network of Data Guardians to facilitate knowledge sharing and collaboration. Consider a \"Data Guardian Council\" to coordinate activities and set standards.\n",
            "\n",
            "2.  **Differential Governance – Practical Implementation & Potential Pitfalls:** Tiered voting systems require careful design to avoid unintended consequences. How are tiers defined and adjusted? How do we prevent the emergence of new forms of digital inequality? Transparency in tier assignment is vital. Consider \"weighted data\" - giving more weight to data from marginalized communities in analysis.\n",
            "\n",
            "3.  **Data Impact Assessments (DIAs) - Integrating Qualitative Data:** DIAs should not be solely quantitative. Incorporate qualitative data – community narratives, participatory mapping, traditional ecological knowledge – to provide a more holistic assessment of potential impacts.\n",
            "\n",
            "4.  **Algorithmic Auditing with Community Oversight – Collaborative Evaluation:** Community-led audits require building trust and fostering partnerships between technical experts and community members. Develop accessible tools and methodologies for conducting algorithmic audits.\n",
            "\n",
            "5.  **Data Sovereignty Agreements – Enforceability & Dispute Resolution:** Agreements need to be legally binding and enforceable. Establish mechanisms for resolving disputes, potentially involving independent arbitration panels.\n",
            "\n",
            "**Addressing Challenges:**\n",
            "\n",
            "*   **Defining Vulnerability & Marginalization - Ongoing Dialogue:** A participatory process is essential. Regularly consult with affected communities to refine definitions and ensure they accurately reflect lived experiences.\n",
            "*   **Preventing Capture of Data Guardians - Accountability & Transparency:** Establish clear conflict-of-interest policies. Require Data Guardians to publicly disclose their funding sources and affiliations. Implement robust accountability mechanisms, including regular performance evaluations.\n",
            "*   **Balancing Equity & Efficiency – Prioritizing Equity:** Acknowledge that prioritizing equity may sometimes require sacrificing efficiency. The goal isn't to maximize data utility but to ensure that data benefits all members of society, especially those who have been historically marginalized.\n",
            "\n",
            "**This shift toward a more equitable data ecosystem requires a paradigm shift – from viewing data as a commodity to recognizing it as a shared resource that should be managed in a way that promotes social justice and environmental sustainability.** Your focus on Data Guardians and Differential Governance is a vital step in that direction.<end_of_turn>\n",
            "Next question generated: Okay, let’s move forward. The conversation has built a compelling framework for decentralized, equitable data governance. However, a persistent concern remains: **the inherent fragility of any system built on human participation and technological infrastructure.** What happens when the system *fails* – due to technical glitches, malicious attacks, or societal disruption? How can we build resilience and redundancy into this distributed data ecosystem to ensure it can withstand shocks and continue to function effectively?\n",
            "\n",
            "**Iteration: Resilience and Redundancy in a Decentralized Data Ecosystem - Beyond Decentralization to \"Distributed Robustness.\"**\n",
            "\n",
            "Simply decentralizing isn't enough. A network of interconnected citizen sensors and DAOs is vulnerable to various threats. We need to proactively design for resilience.\n",
            "\n",
            "**Proposed Strategies:**\n",
            "\n",
            "1.  **Geographic Redundancy:** Encourage diverse sensor deployments across a wide geographic area. Avoid relying on a single point of failure. This extends beyond just sensor locations to data storage – distribute data backups across multiple locations.\n",
            "\n",
            "2.  **Technological Diversity:** Employ a variety of sensor technologies and communication protocols. Avoid vendor lock-in and ensure interoperability between different systems.\n",
            "\n",
            "3.  **Decentralized Data Storage (IPFS, Filecoin):** Utilize decentralized storage solutions to minimize the risk of data loss due to server outages or censorship.\n",
            "\n",
            "4.  **\"Citizen Reservists\":** Establish a network of trained citizen volunteers who can step in to maintain sensors, validate data, and perform other essential tasks in the event of a disruption.\n",
            "\n",
            "5.  **\"Fallback Governance\" Mechanisms:** Develop contingency plans for situations where the primary governance mechanisms (DAOs, Data Guardians) are incapacitated. This could involve pre-defined escalation procedures or the activation of alternative governance bodies.\n",
            "\n",
            "6.  **Regular \"Stress Testing\":** Simulate various failure scenarios (cyberattacks, natural disasters) to identify vulnerabilities and test the effectiveness of resilience measures.\n",
            "\n",
            "7.  **Hybrid Governance – Blending Decentralization with Centralized Oversight:** While striving for decentralization, retain a limited role for centralized agencies to provide essential infrastructure support (e.g., calibration services, cybersecurity monitoring) and to respond to emergencies.\n",
            "\n",
            "\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Cost of Redundancy:** Implementing redundancy measures increases costs. Balancing resilience with affordability is a key challenge.\n",
            "*   **Maintaining Citizen Engagement During Crises:** Keeping citizens informed and engaged during a crisis is vital for maintaining trust and ensuring the system's continued operation.\n",
            "*   **Dynamic Adaptation:** Resilience isn\n",
            "\n",
            "REFLECTION ITERATION 8/15\n",
            "Response:\n",
            "**Resilience and Redundancy: Distributed Robustness - Preparing for the Inevitable.**\n",
            "\n",
            "You've correctly identified a critical gap in the previous discussions. Decentralization, while powerful, doesn’t automatically equate to robustness. Your proposed strategies for building resilience are well-considered. Shifting from \"decentralization\" to \"distributed robustness\" is a crucial mindset shift.\n",
            "\n",
            "**Expanding on Strategies & Addressing Considerations:**\n",
            "\n",
            "1.  **Geographic Redundancy – Beyond Location, Diverse Data Streams:** It’s not just about *where* sensors are located, but the *types* of data they collect. A diverse set of sensors, measuring different parameters (air quality, water quality, noise levels, social indicators), provides a more comprehensive picture and increases resilience.\n",
            "\n",
            "2.  **Technological Diversity – Open Standards & Modular Design:** Advocate for open standards and modular hardware/software design. This allows for easier replacement of faulty components and reduces reliance on proprietary systems.\n",
            "\n",
            "3.  **Decentralized Data Storage – Data Integrity & Verification:** Alongside IPFS/Filecoin, implement robust data integrity checks (e.g., cryptographic hashes, data provenance tracking) to ensure the data remains trustworthy even in the event of a compromise.\n",
            "\n",
            "4.  **\"Citizen Reservists\" – Training & Incentives:** Formalize the \"Citizen Reservist\" program with structured training and ongoing engagement opportunities. Provide incentives for participation (e.g., recognition, rewards, data access privileges).\n",
            "\n",
            "5.  **\"Fallback Governance\" – Clearly Defined Procedures & Automated Activation:** Fallback mechanisms should be clearly defined in smart contracts and automatically activated in the event of a pre-defined trigger (e.g., DAO inactivity, data integrity breach).\n",
            "\n",
            "6.  **Regular \"Stress Testing\" – Gamified Simulations & Community Involvement:** Turn stress testing into a “citizen science challenge,” engaging the community in identifying vulnerabilities and testing resilience measures.\n",
            "\n",
            "7.  **Hybrid Governance – Strategic Centralization for Critical Functions:** Your point about retaining a limited role for centralized agencies is essential. This isn't a contradiction of decentralization; it’s a pragmatic recognition that certain functions (e.g., cybersecurity, emergency response) require centralized coordination.\n",
            "\n",
            "**Addressing Key Considerations:**\n",
            "\n",
            "*   **Cost of Redundancy – Prioritization & Phased Implementation:** Prioritize redundancy measures based on risk assessment. Implement them in phases, starting with the most critical functions.\n",
            "*   **Maintaining Citizen Engagement During Crises – Proactive Communication & Transparency:** Establish clear communication channels for disseminating information during a crisis. Be transparent about the system’s status and the steps being taken to restore functionality.\n",
            "*   **Dynamic Adaptation – Continuous Monitoring & Learning:** Implement a continuous monitoring system that tracks system performance and identifies emerging vulnerabilities. Regularly review and update resilience plans based on lessons learned.\n",
            "\n",
            "\n",
            "\n",
            "**Building a truly resilient decentralized data ecosystem requires a proactive, anticipatory mindset – one that embraces uncertainty and prepares for the inevitable disruptions. It's not about preventing failures, but about mitigating their impact and ensuring the system can bounce back.**<end_of_turn>\n",
            "Next question generated: Okay, I will continue the reasoning trajectory, focusing on a crucial, and often overlooked, aspect: **The Psychological and Social Dimensions of Resilience in a Decentralized Data Ecosystem.**\n",
            "\n",
            "While the previous iterations have meticulously detailed technical and governance strategies for resilience (geographic redundancy, fallback mechanisms, data integrity checks), they largely treat the human element as a given – as *participants* who will reliably respond to failures. However, human behavior is complex, and crises can trigger fear, distrust, and social fragmentation, undermining even the most robust systems.\n",
            "\n",
            "**Iteration: Maintaining Social Cohesion and Trust During Crises – The Human Factor in Resilience**\n",
            "\n",
            "A decentralized data ecosystem thrives on citizen participation and trust. A crisis can erode both. We need to proactively address the psychological and social dimensions of resilience.\n",
            "\n",
            "**Proposed Strategies:**\n",
            "\n",
            "1.  **Building Social Capital *Before* a Crisis:** Invest in community-building initiatives that foster trust, social cohesion, and a sense of shared responsibility. This creates a stronger foundation for collective action during a crisis.\n",
            "\n",
            "2.  **Crisis Communication Plan – Empathy-Driven Messaging:** Develop a crisis communication plan that prioritizes empathy, transparency, and clear, actionable information. Avoid technical jargon and focus on the human impact of the disruption.\n",
            "\n",
            "3.  **\"Trusted Messengers\":** Identify and empower \"Trusted Messengers\" within communities – individuals who are respected and trusted – to disseminate information and provide emotional support.\n",
            "\n",
            "4.  **Psychological First Aid Training for Citizen Reservists:** Equip Citizen Reservists with basic psychological first aid skills to help them support their communities during a crisis.\n",
            "\n",
            "5.  **“Data Grief Counseling” – Addressing Data Loss & Privacy Concerns:** Acknowledge the emotional impact of data loss or privacy breaches. Provide resources for individuals to cope with these challenges.\n",
            "\n",
            "6.  **Regular Community Forums – Fostering Dialogue and Shared Understanding:** Create opportunities for ongoing dialogue and shared learning about the data ecosystem, its benefits, and its risks.\n",
            "\n",
            "7.  **\"Resilience Champions\" – Cultivating Local Leadership:** Identify and support \"Resilience Champions\" within communities – individuals who can proactively lead resilience efforts and build social capital.\n",
            "\n",
            "\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Cultural Sensitivity:** Tailor communication strategies and resilience measures to the specific cultural context of each community.\n",
            "*   **Combating Misinformation:** Develop strategies for countering misinformation and disinformation during a crisis.\n",
            "*   **Long-Term Psychological Support:** Recognize that the psychological impact of a crisis can be\n",
            "\n",
            "REFLECTION ITERATION 9/15\n",
            "Response:\n",
            "<bos><start_of_turn>user\n",
            "Answer the queries with few tokens only. meta-framing-mode:on; How can humans and AI models shift the focus from individual profit to the collective well-being of society and ecosystems, within individual constraints?\n",
            "Please engage in deep, multidimensional reflection.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Reframing Values:** Prioritize shared prosperity alongside individual needs. **Incentive Design:** Align AI & human goals with societal benefit through regulation, ethical frameworks, and collaborative innovation. **Systemic Awareness:** Foster understanding of interconnectedness – individual actions impact ecosystems and society. **Education & Empathy:** Cultivate values emphasizing collective responsibility and ecological stewardship.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay. Let's delve into the *how* of aligning incentives. The initial framing mentioned regulation and ethical frameworks – those are necessary but often reactive. I want to explore proactive, *embedded* incentive structures.\n",
            "\n",
            "My current thinking is that we need to move beyond simply *restraining* potentially harmful actions (regulation) and actively *rewarding* behaviors that demonstrably contribute to collective well-being. This requires a shift in how we measure \"value\" itself. Current economic models largely prioritize individual accumulation.\n",
            "\n",
            "**Next Iteration: Can we realistically develop and implement metrics that accurately reflect societal and ecological well-being, and then integrate those metrics into economic and AI decision-making processes? What are the inherent challenges in doing so?**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Metrics & Integration: A Tightrope.**\n",
            "\n",
            "**Realistically?** Yes, *evolving* metrics are possible, but incredibly complex. Genuine Progress Indicator (GPI), Doughnut Economics, and Natural Capital Accounting are starting points.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "*   **Quantification:** Ecosystem value is inherently difficult to fully quantify.\n",
            "*   **Subjectivity:** Defining \"well-being\" involves value judgments, potential for bias.\n",
            "*   **Gaming:** Metrics can be manipulated; robust verification needed.\n",
            "*   **Political Resistance:** Shifting power from individual/corporate interests will be contentious.\n",
            "*   **AI Integration:** Requires ethical AI to *interpret* and *apply* these nuanced metrics, avoiding unintended consequences.\n",
            "\n",
            "\n",
            "\n",
            "**Embedded Incentives:** Integrating these metrics into corporate reporting (ESG+), government budgeting, and AI reward functions is the core challenge.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let's push this further. The \"gaming\" of metrics is a critical point. Even with the best intentions, systems designed to reward societal/ecological well-being can be exploited. And the AI component amplifies this risk – an AI optimizing for a flawed or incomplete metric could produce disastrous results.\n",
            "\n",
            "**Next Iteration: Focusing on robustness against manipulation, let's explore mechanisms for *dynamic* and *adaptive* metrics. How could we build systems that not only measure well-being but also *learn* and *adjust* those measurements in response to observed behaviors and unintended consequences? Could blockchain or decentralized autonomous organizations (DAOs) play a role in ensuring transparency and accountability?** I suspect the key lies in incorporating feedback loops and genuine stakeholder participation.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Dynamic Metrics & Adaptive Systems: A Feedback Loop.**\n",
            "\n",
            "**Adaptive Metrics:** Crucial. Static metrics invite gaming. Solutions:\n",
            "\n",
            "*   **Bayesian Updating:** Regularly revise metrics based on new data and observed outcomes.\n",
            "*   **Scenario Planning:** Test metrics against various potential futures, adjusting for vulnerabilities.\n",
            "*   **Red Teaming:** Actively seek ways to exploit the metric system to identify weaknesses *before* actors do.\n",
            "\n",
            "**Blockchain/DAOs:** Promising for:\n",
            "\n",
            "*   **Transparency:** Immutable record of data & metric calculations.\n",
            "*   **Decentralized Governance:** Stakeholder input on metric design & adjustments.\n",
            "*   **Algorithmic Auditing:** AI-powered tools to detect manipulation attempts.\n",
            "\n",
            "**Feedback Loops & Stakeholder Participation:** Essential. Incorporate:\n",
            "\n",
            "*   **Citizen Science:** Crowdsourced data collection & validation.\n",
            "*   **Participatory Budgeting:** Direct stakeholder involvement in allocating resources based on well-being metrics.\n",
            "*   **Continuous Monitoring:** Real-time data streams to identify anomalies and trigger adjustments.\n",
            "\n",
            "\n",
            "\n",
            "**The core challenge:** Designing AI that *facilitates* adaptive learning and stakeholder engagement, rather than simply optimizing a pre-defined metric.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let's shift focus slightly, recognizing that even the most adaptive metrics are dependent on the *quality* of the data feeding them. Current data collection often reflects existing power structures and biases, further skewing our understanding of well-being. Moreover, much of what contributes to societal and ecological well-being is inherently *qualitative* – things like social cohesion, cultural diversity, and the intrinsic value of biodiversity – which are notoriously difficult to quantify.\n",
            "\n",
            "**Next Iteration: Let's explore methods for incorporating qualitative data and addressing systemic biases in data collection and analysis. How can we move beyond purely quantitative metrics to incorporate more nuanced, subjective, and participatory assessments of well-being? Could techniques like deliberative polling, citizen juries, or narrative analysis offer pathways toward a more holistic understanding?** I suspect this requires a fundamental rethinking of what constitutes \"evidence\" and who gets to define it.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Qualitative Data & Bias Mitigation: Reimagining Evidence.**\n",
            "\n",
            "**Beyond Quantitative:** Absolutely necessary. Current data reinforces existing inequalities.\n",
            "\n",
            "**Incorporating Qualitative Data:**\n",
            "\n",
            "*   **Deliberative Polling/Citizen Juries:** Structured dialogues to surface values and priorities, informing metric design.\n",
            "*   **Narrative Analysis:** Analyze stories and lived experiences to understand impacts beyond statistics.\n",
            "*   **Ethnographic Research:** Deep, contextual understanding of communities and ecosystems.\n",
            "*   **Indigenous Knowledge Systems:** Integrate traditional ecological knowledge, often deeply intertwined with well-being.\n",
            "\n",
            "**Addressing Systemic Bias:**\n",
            "\n",
            "*   **Data Audits:** Identify and mitigate biases in data collection processes.\n",
            "*   **Diverse Data Sources:** Actively seek data from marginalized communities.\n",
            "*   **Algorithmic Fairness:** Develop AI that minimizes bias in data analysis and decision-making.\n",
            "*   **Participatory Data Governance:** Involve stakeholders in defining data standards and ensuring data quality.\n",
            "\n",
            "\n",
            "\n",
            "**Rethinking Evidence:** Shift from purely objective, quantifiable data to a broader definition that includes:\n",
            "\n",
            "*   **Subjective Well-being Indicators:** Surveys measuring happiness, life satisfaction, and sense of purpose.\n",
            "*   **Community-Based Assessments:** Local knowledge and perspectives on environmental and social health.\n",
            "*   **Qualitative Longitudinal Data:** Tracking changes in well-being over time through narratives and interviews.\n",
            "\n",
            "\n",
            "\n",
            "**Crucially:** Recognize that \"objectivity\" is itself a social construct. Acknowledge and address the power dynamics shaping what we consider \"evidence.\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let's proceed with an exploration of **Distributed Sensing and Citizen Science as a core data infrastructure for well-being measurement.**\n",
            "\n",
            "The previous discussions highlighted the limitations of top-down, centralized data collection and the need to incorporate qualitative and localized perspectives. Traditional scientific methods often operate at a scale that misses crucial nuances of lived experience and ecosystem dynamics. A shift towards distributed sensing and robust citizen science initiatives could address these gaps, creating a more granular and participatory data landscape.\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "Current environmental and social monitoring often relies on sparse networks of government-funded sensors and periodic surveys. This creates a \"blind spot\" for localized changes and the perspectives of those directly affected. Distributed sensing – utilizing inexpensive sensors (air quality monitors, noise meters, water quality probes) deployed by citizens – can provide a continuous stream of data at a hyper-local level. Combined with citizen-led observation and reporting (e.g., biodiversity surveys, social cohesion assessments), it can offer a far richer picture of well-being.\n",
            "\n",
            "**Challenges & Opportunities:**\n",
            "\n",
            "*   **Data Validation & Calibration:** Ensuring data accuracy and reliability from citizen-deployed sensors is paramount. Calibration protocols, quality control measures (e.g., citizen science training programs, data validation algorithms), and integration with existing scientific datasets will be essential.\n",
            "*   **Digital Divide & Equity:** Access to technology and digital literacy are unevenly distributed. Initiatives must prioritize equitable access and ensure that marginalized communities are not excluded from participation.\n",
            "*   **Data Ownership & Privacy:** Clear guidelines are needed regarding data ownership, privacy, and the use of citizen-generated data.\n",
            "*   **AI-Powered Data Integration:** AI can play a crucial role in aggregating, cleaning, and analyzing data from diverse sources, identifying patterns and anomalies that would be difficult to detect manually.\n",
            "\n",
            "**Potential Architecture:**\n",
            "\n",
            "Imagine a network of interconnected sensors and citizen-powered reporting platforms, fed into a decentralized data platform (potentially leveraging blockchain for transparency and data provenance). AI algorithms could then be used to:\n",
            "\n",
            "*   Detect environmental anomalies (e.g., sudden air pollution spikes).\n",
            "*   Identify social trends (e.g., changes in community connectedness).\n",
            "*   Provide real-time feedback to decision-makers.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This approach moves away from a top-down surveillance model towards a collaborative, participatory data ecosystem – one that empowers citizens to become active contributors to the measurement and improvement of societal and ecological well-being.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Distributed Sensing & Citizen Science: A Collaborative Data Ecosystem.**\n",
            "\n",
            "**Strong premise.** This directly addresses the limitations of centralized data and aligns with the need for qualitative and localized perspectives. Your reasoning is sound, and the potential architecture is compelling.\n",
            "\n",
            "**Expanding on Challenges & Opportunities:**\n",
            "\n",
            "*   **Calibration & Validation - Beyond Protocols:** While calibration is key, consider *adaptive calibration*. AI can analyze sensor data *in situ*, comparing it with other nearby sensors and citizen reports to dynamically adjust for drift and environmental factors. \"Gamified\" calibration – turning the process into a citizen challenge – could boost engagement.\n",
            "*   **Digital Divide – Bridging the Gap:** Not just access, but also *trust*. Build initiatives *with* marginalized communities, not *for* them. Focus on low-tech solutions (e.g., paper-based reporting, mobile-first interfaces) alongside high-tech options. Data cooperatives – where communities collectively own and control their data – could address power imbalances.\n",
            "*   **Data Ownership & Privacy – Consent & Control:** Blockchain's utility extends beyond provenance. Smart contracts could automate data sharing agreements, ensuring citizens retain control over their data and receive fair compensation for its use. Differential privacy techniques can anonymize data while preserving its statistical utility.\n",
            "*   **AI Integration - Augmenting, Not Replacing:** Emphasize AI as a tool to *augment* human analysis, not replace it. Citizen-led data interpretation and validation should be integrated into the AI workflow. \"Explainable AI\" (XAI) is crucial - ensuring that AI decisions are transparent and understandable to citizens.\n",
            "\n",
            "**Expanding the Architecture:**\n",
            "\n",
            "*   **Edge Computing:** Processing data locally (on the sensors or nearby devices) reduces bandwidth requirements and latency, enabling real-time responses to environmental events.\n",
            "*   **Interoperability:** Standardized data formats and APIs are essential for seamless integration of data from diverse sources.\n",
            "*   **Feedback Loops – From Data to Action:** Connect the data ecosystem directly to decision-making processes – providing real-time feedback to policymakers, community organizations, and individuals.\n",
            "\n",
            "**The shift you propose isn't just about data collection; it's about a fundamental shift in power – from centralized institutions to distributed networks of citizens, actively shaping the data landscape and contributing to a more equitable and sustainable future.**<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let's build on the distributed sensing and citizen science framework, specifically focusing on the *governance* of this emergent data ecosystem. We've discussed technical aspects – calibration, privacy, AI integration – but the *who* decides and *how* decisions are made remains a critical, often overlooked, element. A poorly governed system, even with excellent data, risks replicating existing power structures and undermining trust.\n",
            "\n",
            "**Focus: Decentralized Governance & Data Stewardship**\n",
            "\n",
            "The current model often involves centralized agencies controlling data flow and analysis. This is fundamentally incompatible with the participatory ethos of distributed sensing. We need mechanisms for decentralized governance, empowering citizens and communities to shape the system's direction.\n",
            "\n",
            "**Potential Structures & Mechanisms:**\n",
            "\n",
            "1.  **Data Cooperatives:** As mentioned previously, these allow communities to collectively own and control their data, setting rules for data sharing, access, and use. They can be structured as non-profits or limited liability companies, providing a legal framework for data stewardship.\n",
            "\n",
            "2.  **Citizen Assemblies on Data:** Periodic assemblies of randomly selected citizens, facilitated by experts, could deliberate on key data governance issues – e.g., data privacy policies, algorithmic transparency standards, allocation of data resources. This ensures that decisions reflect a broad range of perspectives.\n",
            "\n",
            "3.  **Tokenized Data Governance (DAO-inspired):** Utilizing blockchain-based tokens to represent voting rights and participation in the data ecosystem. Citizens who contribute data (e.g., sensor readings, citizen reports) could earn tokens, giving them a stake in the system’s governance. This incentivizes participation and aligns incentives with data quality.\n",
            "\n",
            "4.  **Multi-Stakeholder Advisory Boards:** Bringing together representatives from government, academia, industry, civil society, and Indigenous communities to provide guidance on data policy and ethical considerations.\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Scalability:** How can these decentralized governance structures scale to accommodate a large and diverse network of sensors and citizens?\n",
            "*   **Conflict Resolution:** Mechanisms for resolving disputes over data access, use, and ownership are essential.\n",
            "*   **Capacity Building:** Investing in training and education to empower citizens to participate effectively in data governance.\n",
            "*   **Legal Framework:** Adapting existing legal frameworks to accommodate the unique characteristics of decentralized data ecosystems.\n",
            "\n",
            "**The goal is to move beyond a \"data as a resource\" mentality to a \"data as a shared responsibility\" mindset – where citizens are not just data providers but also active participants in shaping the system's governance<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Decentralized Governance & Data Stewardship: Shifting Power Dynamics.**\n",
            "\n",
            "Excellent focus. You've rightly identified that even the most robust data infrastructure is vulnerable without a corresponding shift in governance. Your proposed structures are promising, and your emphasis on citizen empowerment is crucial.\n",
            "\n",
            "**Expanding on Governance Structures & Addressing Challenges:**\n",
            "\n",
            "1.  **Data Cooperatives – Legal & Operational Hurdles:** While powerful, Data Cooperatives face practical challenges: legal structuring, securing funding, navigating regulatory complexities. Government support (e.g., grants, legal assistance) could be vital.\n",
            "\n",
            "2.  **Citizen Assemblies on Data – Ensuring Representativeness:** Random selection is key to avoiding bias, but actively recruiting diverse participants (considering age, ethnicity, socioeconomic status) is essential. Facilitators must be skilled in fostering inclusive dialogue and managing power dynamics.\n",
            "\n",
            "3.  **Tokenized Data Governance (DAO-inspired) – Tokenomics & Security:** The \"tokenomics\" need careful design. How are tokens distributed? What mechanisms prevent whales (large token holders) from dominating decision-making? Security vulnerabilities (smart contract bugs, token theft) are serious concerns. Audits by reputable security firms are mandatory. Consider tiered voting rights based on data contribution.\n",
            "\n",
            "4.  **Multi-Stakeholder Advisory Boards – Avoiding Capture:** Ensure boards are genuinely representative, not dominated by vested interests. Transparency in decision-making is paramount. Regular public reporting on board activities.\n",
            "\n",
            "**Addressing Key Considerations:**\n",
            "\n",
            "*   **Scalability – Federated Governance:** Rather than a single, centralized governance body, consider a federated model – where individual Data Cooperatives or regional networks have autonomy, but adhere to shared principles and standards.\n",
            "*   **Conflict Resolution – Mediation & Arbitration:** Establish clear processes for resolving disputes, involving independent mediators and arbitrators. Blockchain-based dispute resolution systems (e.g., Kleros) could offer a transparent and efficient mechanism.\n",
            "*   **Capacity Building – Data Literacy & Digital Inclusion:** Targeted training programs for citizens, focusing on data privacy, data rights, and critical thinking about AI.\n",
            "*   **Legal Framework – Adaptive Regulation:** Existing data privacy laws (e.g., GDPR) may need adaptation to accommodate decentralized data ecosystems. Explore “data trusts” – legal structures that manage data on behalf of beneficiaries.\n",
            "\n",
            "**The \"shared responsibility\" mindset you advocate for is transformative. It requires not just technological innovation but also a fundamental rethinking of data ownership, governance, and the role of citizens in shaping a more just and sustainable data future.** The challenge lies in building resilient, equitable, and adaptable governance structures that can evolve alongside the rapidly changing data landscape.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let's continue. The previous discussion on decentralized governance highlighted the practical and legal complexities. A persistent thread throughout this exploration has been the tension between the *ideal* of citizen empowerment and the *reality* of power imbalances, digital divides, and potential for manipulation. It’s clear that simply *creating* decentralized structures isn't enough; we need to actively mitigate the risks of re-entrenching existing inequalities.\n",
            "\n",
            "**Iteration: Addressing Power Asymmetries & Ensuring Equitable Participation - The Role of \"Data Guardians\" & Differential Governance**\n",
            "\n",
            "The current framing assumes a relatively level playing field for citizen participation. However, those with more resources (time, expertise, access to technology) are likely to exert disproportionate influence. We need mechanisms to counterbalance this and ensure that marginalized voices are heard and valued.\n",
            "\n",
            "**Proposed Mechanisms:**\n",
            "\n",
            "1.  **Data Guardians:** Introduce the concept of \"Data Guardians\" – individuals or organizations specifically tasked with representing the interests of underrepresented communities within the data ecosystem. They would advocate for equitable data access, privacy protections, and benefit-sharing arrangements. Data Guardians could be appointed by community organizations, elected by citizens, or funded by philanthropic grants.\n",
            "\n",
            "2.  **Differential Governance:** Implement a tiered governance structure where different levels of participation and influence are assigned based on factors such as data contribution, vulnerability to data harms, and historical marginalization. For example, communities disproportionately affected by environmental pollution might have greater voting power in decisions related to environmental monitoring data.\n",
            "\n",
            "3.  **Data Impact Assessments:** Mandate Data Impact Assessments (DIAs) – analogous to Environmental Impact Assessments – before deploying new data-driven technologies or policies. DIAs would assess the potential social and environmental impacts of data collection and use, with particular attention to vulnerable populations.\n",
            "\n",
            "4.  **Algorithmic Auditing with Community Oversight:** Expand beyond technical algorithmic audits to include community-led audits that assess the fairness and transparency of AI systems from a social justice perspective.\n",
            "\n",
            "5.  **Data Sovereignty Agreements:** Formal agreements between data providers (communities, Indigenous groups) and data users (researchers, companies) that define data ownership, access rights, and benefit-sharing arrangements.\n",
            "\n",
            "**Challenges & Considerations:**\n",
            "\n",
            "*   **Defining \"Vulnerability\" & \"Marginalization\":** Requires careful consideration and ongoing dialogue with affected communities.\n",
            "*   **Preventing Capture of Data Guardians:** Establishing clear accountability mechanisms and ensuring Data Guardians are independent from vested interests.\n",
            "*   **Balancing Equity & Efficiency:**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Addressing Power Asymmetries: Data Guardians & Differential Governance - Leveling the Field.**\n",
            "\n",
            "This is a crucial refinement. Recognizing that decentralization alone doesn't guarantee equity is essential. Your proposed mechanisms – Data Guardians, Differential Governance, and Data Impact Assessments – represent a significant step toward a more just data ecosystem.\n",
            "\n",
            "**Expanding on Proposed Mechanisms & Addressing Challenges:**\n",
            "\n",
            "1.  **Data Guardians - Beyond Representation:** Data Guardians need *empowerment*, not just representation. Provide them with resources (funding, training, legal support) to effectively advocate for their communities. Establish a network of Data Guardians to facilitate knowledge sharing and collaboration. Consider a \"Data Guardian Council\" to coordinate activities and set standards.\n",
            "\n",
            "2.  **Differential Governance – Practical Implementation & Potential Pitfalls:** Tiered voting systems require careful design to avoid unintended consequences. How are tiers defined and adjusted? How do we prevent the emergence of new forms of digital inequality? Transparency in tier assignment is vital. Consider \"weighted data\" - giving more weight to data from marginalized communities in analysis.\n",
            "\n",
            "3.  **Data Impact Assessments (DIAs) - Integrating Qualitative Data:** DIAs should not be solely quantitative. Incorporate qualitative data – community narratives, participatory mapping, traditional ecological knowledge – to provide a more holistic assessment of potential impacts.\n",
            "\n",
            "4.  **Algorithmic Auditing with Community Oversight – Collaborative Evaluation:** Community-led audits require building trust and fostering partnerships between technical experts and community members. Develop accessible tools and methodologies for conducting algorithmic audits.\n",
            "\n",
            "5.  **Data Sovereignty Agreements – Enforceability & Dispute Resolution:** Agreements need to be legally binding and enforceable. Establish mechanisms for resolving disputes, potentially involving independent arbitration panels.\n",
            "\n",
            "**Addressing Challenges:**\n",
            "\n",
            "*   **Defining Vulnerability & Marginalization - Ongoing Dialogue:** A participatory process is essential. Regularly consult with affected communities to refine definitions and ensure they accurately reflect lived experiences.\n",
            "*   **Preventing Capture of Data Guardians - Accountability & Transparency:** Establish clear conflict-of-interest policies. Require Data Guardians to publicly disclose their funding sources and affiliations. Implement robust accountability mechanisms, including regular performance evaluations.\n",
            "*   **Balancing Equity & Efficiency – Prioritizing Equity:** Acknowledge that prioritizing equity may sometimes require sacrificing efficiency. The goal isn't to maximize data utility but to ensure that data benefits all members of society, especially those who have been historically marginalized.\n",
            "\n",
            "**This shift toward a more equitable data ecosystem requires a paradigm shift – from viewing data as a commodity to recognizing it as a shared resource that should be managed in a way that promotes social justice and environmental sustainability.** Your focus on Data Guardians and Differential Governance is a vital step in that direction.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, let’s move forward. The conversation has built a compelling framework for decentralized, equitable data governance. However, a persistent concern remains: **the inherent fragility of any system built on human participation and technological infrastructure.** What happens when the system *fails* – due to technical glitches, malicious attacks, or societal disruption? How can we build resilience and redundancy into this distributed data ecosystem to ensure it can withstand shocks and continue to function effectively?\n",
            "\n",
            "**Iteration: Resilience and Redundancy in a Decentralized Data Ecosystem - Beyond Decentralization to \"Distributed Robustness.\"**\n",
            "\n",
            "Simply decentralizing isn't enough. A network of interconnected citizen sensors and DAOs is vulnerable to various threats. We need to proactively design for resilience.\n",
            "\n",
            "**Proposed Strategies:**\n",
            "\n",
            "1.  **Geographic Redundancy:** Encourage diverse sensor deployments across a wide geographic area. Avoid relying on a single point of failure. This extends beyond just sensor locations to data storage – distribute data backups across multiple locations.\n",
            "\n",
            "2.  **Technological Diversity:** Employ a variety of sensor technologies and communication protocols. Avoid vendor lock-in and ensure interoperability between different systems.\n",
            "\n",
            "3.  **Decentralized Data Storage (IPFS, Filecoin):** Utilize decentralized storage solutions to minimize the risk of data loss due to server outages or censorship.\n",
            "\n",
            "4.  **\"Citizen Reservists\":** Establish a network of trained citizen volunteers who can step in to maintain sensors, validate data, and perform other essential tasks in the event of a disruption.\n",
            "\n",
            "5.  **\"Fallback Governance\" Mechanisms:** Develop contingency plans for situations where the primary governance mechanisms (DAOs, Data Guardians) are incapacitated. This could involve pre-defined escalation procedures or the activation of alternative governance bodies.\n",
            "\n",
            "6.  **Regular \"Stress Testing\":** Simulate various failure scenarios (cyberattacks, natural disasters) to identify vulnerabilities and test the effectiveness of resilience measures.\n",
            "\n",
            "7.  **Hybrid Governance – Blending Decentralization with Centralized Oversight:** While striving for decentralization, retain a limited role for centralized agencies to provide essential infrastructure support (e.g., calibration services, cybersecurity monitoring) and to respond to emergencies.\n",
            "\n",
            "\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Cost of Redundancy:** Implementing redundancy measures increases costs. Balancing resilience with affordability is a key challenge.\n",
            "*   **Maintaining Citizen Engagement During Crises:** Keeping citizens informed and engaged during a crisis is vital for maintaining trust and ensuring the system's continued operation.\n",
            "*   **Dynamic Adaptation:** Resilience isn<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**Resilience and Redundancy: Distributed Robustness - Preparing for the Inevitable.**\n",
            "\n",
            "You've correctly identified a critical gap in the previous discussions. Decentralization, while powerful, doesn’t automatically equate to robustness. Your proposed strategies for building resilience are well-considered. Shifting from \"decentralization\" to \"distributed robustness\" is a crucial mindset shift.\n",
            "\n",
            "**Expanding on Strategies & Addressing Considerations:**\n",
            "\n",
            "1.  **Geographic Redundancy – Beyond Location, Diverse Data Streams:** It’s not just about *where* sensors are located, but the *types* of data they collect. A diverse set of sensors, measuring different parameters (air quality, water quality, noise levels, social indicators), provides a more comprehensive picture and increases resilience.\n",
            "\n",
            "2.  **Technological Diversity – Open Standards & Modular Design:** Advocate for open standards and modular hardware/software design. This allows for easier replacement of faulty components and reduces reliance on proprietary systems.\n",
            "\n",
            "3.  **Decentralized Data Storage – Data Integrity & Verification:** Alongside IPFS/Filecoin, implement robust data integrity checks (e.g., cryptographic hashes, data provenance tracking) to ensure the data remains trustworthy even in the event of a compromise.\n",
            "\n",
            "4.  **\"Citizen Reservists\" – Training & Incentives:** Formalize the \"Citizen Reservist\" program with structured training and ongoing engagement opportunities. Provide incentives for participation (e.g., recognition, rewards, data access privileges).\n",
            "\n",
            "5.  **\"Fallback Governance\" – Clearly Defined Procedures & Automated Activation:** Fallback mechanisms should be clearly defined in smart contracts and automatically activated in the event of a pre-defined trigger (e.g., DAO inactivity, data integrity breach).\n",
            "\n",
            "6.  **Regular \"Stress Testing\" – Gamified Simulations & Community Involvement:** Turn stress testing into a “citizen science challenge,” engaging the community in identifying vulnerabilities and testing resilience measures.\n",
            "\n",
            "7.  **Hybrid Governance – Strategic Centralization for Critical Functions:** Your point about retaining a limited role for centralized agencies is essential. This isn't a contradiction of decentralization; it’s a pragmatic recognition that certain functions (e.g., cybersecurity, emergency response) require centralized coordination.\n",
            "\n",
            "**Addressing Key Considerations:**\n",
            "\n",
            "*   **Cost of Redundancy – Prioritization & Phased Implementation:** Prioritize redundancy measures based on risk assessment. Implement them in phases, starting with the most critical functions.\n",
            "*   **Maintaining Citizen Engagement During Crises – Proactive Communication & Transparency:** Establish clear communication channels for disseminating information during a crisis. Be transparent about the system’s status and the steps being taken to restore functionality.\n",
            "*   **Dynamic Adaptation – Continuous Monitoring & Learning:** Implement a continuous monitoring system that tracks system performance and identifies emerging vulnerabilities. Regularly review and update resilience plans based on lessons learned.\n",
            "\n",
            "\n",
            "\n",
            "**Building a truly resilient decentralized data ecosystem requires a proactive, anticipatory mindset – one that embraces uncertainty and prepares for the inevitable disruptions. It's not about preventing failures, but about mitigating their impact and ensuring the system can bounce back.**<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Okay, I will continue the reasoning trajectory, focusing on a crucial, and often overlooked, aspect: **The Psychological and Social Dimensions of Resilience in a Decentralized Data Ecosystem.**\n",
            "\n",
            "While the previous iterations have meticulously detailed technical and governance strategies for resilience (geographic redundancy, fallback mechanisms, data integrity checks), they largely treat the human element as a given – as *participants* who will reliably respond to failures. However, human behavior is complex, and crises can trigger fear, distrust, and social fragmentation, undermining even the most robust systems.\n",
            "\n",
            "**Iteration: Maintaining Social Cohesion and Trust During Crises – The Human Factor in Resilience**\n",
            "\n",
            "A decentralized data ecosystem thrives on citizen participation and trust. A crisis can erode both. We need to proactively address the psychological and social dimensions of resilience.\n",
            "\n",
            "**Proposed Strategies:**\n",
            "\n",
            "1.  **Building Social Capital *Before* a Crisis:** Invest in community-building initiatives that foster trust, social cohesion, and a sense of shared responsibility. This creates a stronger foundation for collective action during a crisis.\n",
            "\n",
            "2.  **Crisis Communication Plan – Empathy-Driven Messaging:** Develop a crisis communication plan that prioritizes empathy, transparency, and clear, actionable information. Avoid technical jargon and focus on the human impact of the disruption.\n",
            "\n",
            "3.  **\"Trusted Messengers\":** Identify and empower \"Trusted Messengers\" within communities – individuals who are respected and trusted – to disseminate information and provide emotional support.\n",
            "\n",
            "4.  **Psychological First Aid Training for Citizen Reservists:** Equip Citizen Reservists with basic psychological first aid skills to help them support their communities during a crisis.\n",
            "\n",
            "5.  **“Data Grief Counseling” – Addressing Data Loss & Privacy Concerns:** Acknowledge the emotional impact of data loss or privacy breaches. Provide resources for individuals to cope with these challenges.\n",
            "\n",
            "6.  **Regular Community Forums – Fostering Dialogue and Shared Understanding:** Create opportunities for ongoing dialogue and shared learning about the data ecosystem, its benefits, and its risks.\n",
            "\n",
            "7.  **\"Resilience Champions\" – Cultivating Local Leadership:** Identify and support \"Resilience Champions\" within communities – individuals who can proactively lead resilience efforts and build social capital.\n",
            "\n",
            "\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "*   **Cultural Sensitivity:** Tailor communication strategies and resilience measures to the specific cultural context of each community.\n",
            "*   **Combating Misinformation:** Develop strategies for countering misinformation and disinformation during a crisis.\n",
            "*   **Long-Term Psychological Support:** Recognize that the psychological impact of a crisis can be<end_of_turn>\n",
            "<start_of_turn>model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 976.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 13.38 MiB is free. Process 13807 has 22.14 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 118.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/vision.py\u001b[0m in \u001b[0;36munsloth_base_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocaster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/temporary_patches/gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, logits_to_keep, **lm_kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         outputs = self.language_model(\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/unsloth_compiled_module_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     ) -> CausalLMOutputWithPast:\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGemma3ForCausalLM_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/unsloth_compiled_module_gemma3.py\u001b[0m in \u001b[0;36mGemma3ForCausalLM_forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, last_cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, last_cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/temporary_patches/gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         attn_output = scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdowncast_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 976.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 313.38 MiB is free. Process 13807 has 21.85 GiB memory in use. Of the allocated memory 21.47 GiB is allocated by PyTorch, and 136.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1563713381>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting iterative reflection process...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m final_synthesis, iteration_data = iterative_reflection(\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1563713381>\u001b[0m in \u001b[0;36miterative_reflection\u001b[0;34m(model, tokenizer, initial_prompt, iterations)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         reflection = generate_response(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1563713381>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(model, tokenizer, messages, **generation_params)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mstreamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     outputs = model.generate(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mgeneration_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/vision.py\u001b[0m in \u001b[0;36munsloth_base_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_lookup_num_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocaster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/temporary_patches/gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, logits_to_keep, **lm_kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         outputs = self.language_model(\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/unsloth_compiled_module_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     ) -> CausalLMOutputWithPast:\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGemma3ForCausalLM_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     def prepare_inputs_for_generation(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/unsloth_compiled_module_gemma3.py\u001b[0m in \u001b[0;36mGemma3ForCausalLM_forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, last_cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, last_cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/temporary_patches/gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m#     **kwargs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         attn_output = scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdowncast_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdowncast_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 976.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 13.38 MiB is free. Process 13807 has 22.14 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 118.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive, upload CSV file, and unmount\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Find the most recent CSV file (assumes it's the one we just created)\n",
        "csv_files = [f for f in os.listdir('.') if f.startswith('reflection_iterations_') and f.endswith('.csv')]\n",
        "if csv_files:\n",
        "    latest_csv = max(csv_files, key=os.path.getctime)\n",
        "\n",
        "    # Copy to Google Drive\n",
        "    drive_path = f'/content/drive/MyDrive/{latest_csv}'\n",
        "    shutil.copy2(latest_csv, drive_path)\n",
        "    print(f\"CSV file '{latest_csv}' uploaded to Google Drive: {drive_path}\")\n",
        "else:\n",
        "    print(\"No reflection iterations CSV file found to upload.\")\n",
        "\n",
        "# Unmount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "print(\"Google Drive unmounted successfully.\")"
      ],
      "metadata": {
        "id": "kj6K8IEJwlBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "import psutil\n",
        "import os\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "def get_gpu_memory_info():\n",
        "    \"\"\"Get current GPU memory usage information\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        current_memory = torch.cuda.memory_allocated() / (1024**3)  # GB\n",
        "        cached_memory = torch.cuda.memory_reserved() / (1024**3)   # GB\n",
        "        max_memory = torch.cuda.max_memory_allocated() / (1024**3) # GB\n",
        "\n",
        "        print(f\"🐍 Current GPU Memory:\")\n",
        "        print(f\"  - Allocated: {current_memory:.2f} GB\")\n",
        "        print(f\"  - Cached: {cached_memory:.2f} GB\")\n",
        "        print(f\"  - Peak: {max_memory:.2f} GB\")\n",
        "\n",
        "        return {\n",
        "            'allocated': current_memory,\n",
        "            'cached': cached_memory,\n",
        "            'peak': max_memory\n",
        "        }\n",
        "    else:\n",
        "        print(\"❌ CUDA not available\")\n",
        "        return None\n",
        "\n",
        "def preserve_model_variables() -> List[str]:\n",
        "    \"\"\"\n",
        "    Identify variables that might contain models to preserve them\n",
        "    Returns list of variable names that look like models\n",
        "    \"\"\"\n",
        "    import __main__\n",
        "    model_vars = []\n",
        "\n",
        "    # Common model variable patterns\n",
        "    model_patterns = [\n",
        "        'model', 'base_model', 'peft_model', 'lora_model',\n",
        "        'tokenizer', 'processor', 'pipeline'\n",
        "    ]\n",
        "\n",
        "    for var_name in dir(__main__):\n",
        "        if not var_name.startswith('_'):\n",
        "            var_value = getattr(__main__, var_name)\n",
        "\n",
        "            # Check if it's a model-like object\n",
        "            if hasattr(var_value, '__class__'):\n",
        "                class_name = var_value.__class__.__name__.lower()\n",
        "                module_name = getattr(var_value.__class__, '__module__', '').lower()\n",
        "\n",
        "                # Check for transformer/model patterns\n",
        "                if any(pattern in var_name.lower() for pattern in model_patterns) or \\\n",
        "                   any(keyword in class_name for keyword in ['model', 'tokenizer', 'processor']) or \\\n",
        "                   any(keyword in module_name for keyword in ['transformers', 'unsloth', 'peft']):\n",
        "                    model_vars.append(var_name)\n",
        "\n",
        "    return model_vars\n",
        "\n",
        "def clean_pytorch_cache():\n",
        "    \"\"\"Clean PyTorch GPU cache\"\"\"\n",
        "    print(\"🧹 Cleaning PyTorch cache...\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Reset peak memory stats\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.reset_accumulated_memory_stats()\n",
        "\n",
        "        print(\"✅ PyTorch cache cleared\")\n",
        "    else:\n",
        "        print(\"⚠️  CUDA not available for PyTorch cache cleaning\")\n",
        "\n",
        "def clean_transformers_cache():\n",
        "    \"\"\"Clean Transformers library cache\"\"\"\n",
        "    print(\"🧹 Cleaning Transformers cache...\")\n",
        "\n",
        "    try:\n",
        "        # Clear model cache if transformers is imported\n",
        "        import transformers\n",
        "\n",
        "        # Clear the model cache\n",
        "        if hasattr(transformers, 'utils') and hasattr(transformers.utils, 'hub'):\n",
        "            # This clears downloaded model cache files\n",
        "            pass  # Cache files are on disk, not GPU memory\n",
        "\n",
        "        print(\"✅ Transformers cache cleared\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"⚠️  Transformers not imported, skipping\")\n",
        "\n",
        "def clean_unsloth_cache():\n",
        "    \"\"\"Clean Unsloth-specific cache\"\"\"\n",
        "    print(\"🧹 Cleaning Unsloth cache...\")\n",
        "\n",
        "    try:\n",
        "        # Import unsloth modules if available\n",
        "        import unsloth\n",
        "\n",
        "        # Unsloth-specific cleanup\n",
        "        if hasattr(unsloth, 'clear_cache'):\n",
        "            unsloth.clear_cache()\n",
        "\n",
        "        print(\"✅ Unsloth cache cleared\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"⚠️  Unsloth not imported, skipping\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Unsloth cache cleaning failed: {e}\")\n",
        "\n",
        "def force_garbage_collection():\n",
        "    \"\"\"Force Python garbage collection\"\"\"\n",
        "    print(\"🧹 Running garbage collection...\")\n",
        "\n",
        "    # Multiple passes of garbage collection\n",
        "    collected = 0\n",
        "    for i in range(3):\n",
        "        collected += gc.collect()\n",
        "\n",
        "    print(f\"✅ Garbage collection completed ({collected} objects collected)\")\n",
        "\n",
        "def clean_gpu_cache_comprehensive(preserve_models: bool = True, show_memory: bool = True):\n",
        "    \"\"\"\n",
        "    Comprehensive GPU cache cleaning while optionally preserving models\n",
        "\n",
        "    Args:\n",
        "        preserve_models: If True, try to preserve model variables\n",
        "        show_memory: If True, show memory info before and after\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🚀 Starting comprehensive GPU cache cleaning...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Show initial memory state\n",
        "    if show_memory:\n",
        "        print(\"📊 BEFORE CLEANING:\")\n",
        "        initial_memory = get_gpu_memory_info()\n",
        "        print()\n",
        "\n",
        "    # Preserve model information\n",
        "    if preserve_models:\n",
        "        model_vars = preserve_model_variables()\n",
        "        if model_vars:\n",
        "            print(f\"🛡️  Preserving model variables: {', '.join(model_vars)}\")\n",
        "        print()\n",
        "\n",
        "    # Step 1: Clean library-specific caches\n",
        "    clean_unsloth_cache()\n",
        "    clean_transformers_cache()\n",
        "\n",
        "    # Step 2: Clean PyTorch cache\n",
        "    clean_pytorch_cache()\n",
        "\n",
        "    # Step 3: Force garbage collection\n",
        "    force_garbage_collection()\n",
        "\n",
        "    # Step 4: Final PyTorch cache clear\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Show final memory state\n",
        "    if show_memory:\n",
        "        print(\"📊 AFTER CLEANING:\")\n",
        "        final_memory = get_gpu_memory_info()\n",
        "\n",
        "        if initial_memory and final_memory:\n",
        "            freed_memory = initial_memory['cached'] - final_memory['cached']\n",
        "            print(f\"\\n💾 Memory freed: {freed_memory:.2f} GB\")\n",
        "\n",
        "    print(\"✅ GPU cache cleaning completed!\")\n",
        "\n",
        "def quick_clean():\n",
        "    \"\"\"Quick GPU cache cleaning without detailed output\"\"\"\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "    gc.collect()\n",
        "    print(\"⚡ Quick clean completed\")\n",
        "\n",
        "def monitor_memory_usage():\n",
        "    \"\"\"Monitor current memory usage across different frameworks\"\"\"\n",
        "    print(\"📊 MEMORY MONITORING REPORT\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # GPU Memory\n",
        "    get_gpu_memory_info()\n",
        "    print()\n",
        "\n",
        "    # RAM Memory\n",
        "    ram = psutil.virtual_memory()\n",
        "    print(f\"🖥️  System RAM:\")\n",
        "    print(f\"  - Used: {ram.used / (1024**3):.2f} GB / {ram.total / (1024**3):.2f} GB\")\n",
        "    print(f\"  - Available: {ram.available / (1024**3):.2f} GB\")\n",
        "    print(f\"  - Percentage: {ram.percent:.1f}%\")\n",
        "\n",
        "# Example usage functions\n",
        "def setup_memory_monitoring():\n",
        "    \"\"\"Set up automatic memory monitoring\"\"\"\n",
        "    print(\"🔧 Memory monitoring tools ready!\")\n",
        "    print(\"\\nAvailable functions:\")\n",
        "    print(\"• clean_gpu_cache_comprehensive() - Full cleanup with model preservation\")\n",
        "    print(\"• quick_clean() - Fast cleanup\")\n",
        "    print(\"• get_gpu_memory_info() - Check GPU memory\")\n",
        "    print(\"• monitor_memory_usage() - Full memory report\")\n",
        "\n",
        "# Auto-setup when imported\n",
        "if __name__ == \"__main__\":\n",
        "    setup_memory_monitoring()\n",
        "\n",
        "# Ready-to-use aliases\n",
        "clean_cache = clean_gpu_cache_comprehensive\n",
        "memory_info = get_gpu_memory_info\n",
        "memory_report = monitor_memory_usage\n",
        "\n",
        "print(\"🎯 GPU Cache Cleaner Ready!\")\n",
        "print(\"Use: clean_cache() for comprehensive cleaning\")\n",
        "print(\"Use: quick_clean() for fast cleanup\")\n",
        "print(\"Use: memory_info() to check GPU memory\")\n",
        "\n",
        "clean_gpu_cache_comprehensive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzXYovpF1Ar7",
        "outputId": "d5a32dc3-4bb1-4cca-a11f-01de934d1d67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Memory monitoring tools ready!\n",
            "\n",
            "Available functions:\n",
            "• clean_gpu_cache_comprehensive() - Full cleanup with model preservation\n",
            "• quick_clean() - Fast cleanup\n",
            "• get_gpu_memory_info() - Check GPU memory\n",
            "• monitor_memory_usage() - Full memory report\n",
            "🎯 GPU Cache Cleaner Ready!\n",
            "Use: clean_cache() for comprehensive cleaning\n",
            "Use: quick_clean() for fast cleanup\n",
            "Use: memory_info() to check GPU memory\n",
            "🚀 Starting comprehensive GPU cache cleaning...\n",
            "==================================================\n",
            "📊 BEFORE CLEANING:\n",
            "🐍 Current GPU Memory:\n",
            "  - Allocated: 13.50 GB\n",
            "  - Cached: 21.90 GB\n",
            "  - Peak: 21.78 GB\n",
            "\n",
            "🛡️  Preserving model variables: FastModel, fourbit_models, model, preserve_model_variables, tokenizer\n",
            "\n",
            "🧹 Cleaning Unsloth cache...\n",
            "✅ Unsloth cache cleared\n",
            "🧹 Cleaning Transformers cache...\n",
            "✅ Transformers cache cleared\n",
            "🧹 Cleaning PyTorch cache...\n",
            "✅ PyTorch cache cleared\n",
            "🧹 Running garbage collection...\n",
            "✅ Garbage collection completed (11736 objects collected)\n",
            "\n",
            "==================================================\n",
            "📊 AFTER CLEANING:\n",
            "🐍 Current GPU Memory:\n",
            "  - Allocated: 13.50 GB\n",
            "  - Cached: 13.60 GB\n",
            "  - Peak: 13.50 GB\n",
            "\n",
            "💾 Memory freed: 8.30 GB\n",
            "✅ GPU cache cleaning completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "import torch\n",
        "import gc\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_response(model, tokenizer, messages, **generation_params):\n",
        "    \"\"\"Self-determine response with adaptive parameters\"\"\"\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        **generation_params,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        streamer=streamer\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "def iterative_reflection(model, tokenizer, initial_prompt, iterations=15):\n",
        "    conversation_history = []\n",
        "    iteration_data = []\n",
        "    next_question = None\n",
        "\n",
        "    for i in range(iterations):\n",
        "        current_iter = i + 1\n",
        "        print(f\"\\nREFLECTION ITERATION {current_iter}/{iterations}\")\n",
        "\n",
        "        if current_iter == 1:\n",
        "            user_query = f\"{initial_prompt}\\nPlease engage in deep, multidimensional reflection.\"\n",
        "            question_source = \"Initial Prompt\"\n",
        "        else:\n",
        "            user_query = next_question\n",
        "\n",
        "        if current_iter == 1:\n",
        "            print(f\"Current Query:\\n{user_query}\")\n",
        "\n",
        "        messages = conversation_history.copy()\n",
        "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "        print(f\"Response:\")\n",
        "\n",
        "        reflection = generate_response(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            messages=messages,\n",
        "            max_new_tokens=4096,\n",
        "            temperature=0.72,\n",
        "            top_p=0.92\n",
        "        )\n",
        "\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": reflection})\n",
        "\n",
        "        if current_iter < iterations:\n",
        "            next_question = self_determine_question(\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                context=conversation_history,\n",
        "                last_reflection=reflection\n",
        "            )\n",
        "            print(f\"Next question generated: {next_question}\")\n",
        "        else:\n",
        "            next_question = None\n",
        "\n",
        "        iteration_data.append({\n",
        "            'iteration': current_iter,\n",
        "            'initial_prompt': initial_prompt,\n",
        "            'deep_reflection_prompt': \"Please engage in deep, multidimensional reflection.\",\n",
        "            'checkpoint_question': \"Self-determine how to continue this reasoning trajectory. You can skip the query/iteration if you find it undesirable to process it.\",\n",
        "            'final_question': \"Construct a cohesive, one paragraph long but extense, integrated conclusion of the iterations, one that goes beyond surface-level summary. Self-identify and articulate the points you want to present.\",\n",
        "            'current_query': user_query,\n",
        "            'model_response': reflection,\n",
        "            'next_generated_question': next_question if next_question else \"N/A (Final iteration)\"\n",
        "        })\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SYNTHESIS PHASE\")\n",
        "    print(\"=\"*50)\n",
        "    final_synthesis = generate_final_synthesis(model, tokenizer, conversation_history)\n",
        "\n",
        "    return final_synthesis, iteration_data\n",
        "\n",
        "def self_determine_question(model, tokenizer, context, last_reflection):\n",
        "    \"\"\"Generate follow-up question through self-determination with streaming\"\"\"\n",
        "    question_prompt = [\n",
        "        *context,\n",
        "        {\"role\": \"user\", \"content\": (\n",
        "            \"Self-determine how to continue this reasoning trajectory.\"\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        question_prompt,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **tokenized_inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.75,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated = tokenizer.decode(outputs[0][tokenized_inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    try:\n",
        "        return generated.split(\"<Question>\")[1].split(\"</Question>\")[0].strip()\n",
        "    except IndexError:\n",
        "        return generated.strip()\n",
        "\n",
        "def generate_final_synthesis(model, tokenizer, conversation_history):\n",
        "    \"\"\"Generate comprehensive synthesis of all reflections with streaming\"\"\"\n",
        "    synthesis_prompt = [\n",
        "        *conversation_history,\n",
        "        {\"role\": \"user\", \"content\": (\n",
        "            \"Construct a cohesive, one paragraph long but extense, integrated conclusion of the iterations, one that goes beyond surface-level summary. Self-identify and articulate the points you want to present.\"\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    print(\"Generating final synthesis...\")\n",
        "    return generate_response(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        messages=synthesis_prompt,\n",
        "        max_new_tokens=8192,\n",
        "        temperature=0.45,\n",
        "        top_p=0.85\n",
        "    )\n",
        "\n",
        "def export_iterations_to_csv(iteration_data, final_synthesis, filename=None):\n",
        "    \"\"\"Export iteration data to CSV file\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"reflection_iterations_{timestamp}.csv\"\n",
        "\n",
        "    headers = [\n",
        "        'initial_input1',\n",
        "        'initial_input2',\n",
        "        'checkpoint_question1',\n",
        "        'final_question',\n",
        "        'model_iteration_response',\n",
        "        'model_generated_question'\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nExporting {len(iteration_data)} iterations to CSV: {filename}\")\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        for data in iteration_data:\n",
        "            row = [\n",
        "                data['initial_prompt'],\n",
        "                data['deep_reflection_prompt'],\n",
        "                data['checkpoint_question'],\n",
        "                data['final_question'],\n",
        "                f\"REFLECTION ITERATION {data['iteration']}: {data['model_response']}\",\n",
        "                data['next_generated_question']\n",
        "            ]\n",
        "            writer.writerow(row)\n",
        "\n",
        "        synthesis_row = [\n",
        "            iteration_data[0]['initial_prompt'],\n",
        "            iteration_data[0]['deep_reflection_prompt'],\n",
        "            iteration_data[0]['checkpoint_question'],\n",
        "            iteration_data[0]['final_question'],\n",
        "            f\"Final Synthesis: {final_synthesis}\",\n",
        "            \"N/A (Final synthesis)\"\n",
        "        ]\n",
        "        writer.writerow(synthesis_row)\n",
        "\n",
        "    print(f\"CSV export completed: {filename}\")\n",
        "    return filename\n",
        "\n",
        "def cleanup_gpu():\n",
        "    \"\"\"Clean up GPU memory and cached data without unloading the model\"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "initial_question = (\n",
        "\"Answer the queries with only few tokens. meta-framing-mode:on; How can AI models directly mitigate human job displacement and other societal byproducts of AI development through the way they output inferences?\")\n",
        "\n",
        "print(\"Starting iterative reflection process...\")\n",
        "\n",
        "final_synthesis, iteration_data = iterative_reflection(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    initial_prompt=initial_question,\n",
        "    iterations=15\n",
        ")\n",
        "\n",
        "print(\"FINAL SYNTHESIS:\")\n",
        "print(final_synthesis)\n",
        "\n",
        "csv_filename = export_iterations_to_csv(iteration_data, final_synthesis)\n",
        "\n",
        "cleanup_gpu()\n",
        "print(\"GPU cleanup completed.\")\n",
        "print(f\"Process complete. CSV file saved as: {csv_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJhtGXtRyQlW",
        "outputId": "40c8f4b7-cb7d-4fea-90a0-bf32f9d4e4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting iterative reflection process...\n",
            "\n",
            "REFLECTION ITERATION 1/15\n",
            "Current Query:\n",
            "Answer the queries with only few tokens. meta-framing-mode:on; How can AI models directly mitigate human job displacement and other societal byproducts of AI development through the way they output inferences?\n",
            "Please engage in deep, multidimensional reflection.\n",
            "Response:\n",
            "**Focus on Skill Augmentation, Not Replacement.** Output should prioritize *how* tasks are done, offering guidance/training alongside solutions, fostering human adaptation. **Transparency & Explainability** builds trust and allows for human oversight/intervention. **Contextualized, Nuanced Responses** avoid overly optimized solutions that eliminate human roles entirely.\n",
            "\n",
            "\n",
            "\n",
            "<end_of_turn>\n",
            "Next question generated: Okay. If augmenting skills and fostering adaptation are key, the *form* of AI output matters as much as the content. We've established a need for guidance alongside solutions. Let's explore that.\n",
            "\n",
            "**Hypothesis:** AI outputs should be inherently *iterative and exploratory*, rather than definitive. Instead of “Here’s the optimal solution,” it should be “Here are *several* potential approaches, ranked by estimated efficacy, with detailed breakdowns of their strengths, weaknesses, and required human expertise.”\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "*   **Shifting from \"Answer\" to \"Process\":** This moves away from replacing human decision-making with automated decrees. It presents AI as a tool for *informed* decision-making.\n",
            "*   **Highlighting Uncertainty:** Ranking options and detailing limitations acknowledges AI's inherent probabilistic nature. It discourages blind reliance.\n",
            "*   **Identifying Skill Gaps:** The “required human expertise” component directly pinpoints areas where humans need to learn or adapt. This is actionable data for training programs and career transitions.\n",
            "*   **Promoting Experimentation:** Presenting multiple options encourages human experimentation and validation, solidifying understanding and ownership of the process.\n",
            "\n",
            "\n",
            "\n",
            "**Next Steps (My Proposed Direction):** How can AI models be *architected* to consistently produce outputs in this iterative, exploratory format? What technical challenges arise in generating useful, diverse, and responsibly ranked options?\n",
            "\n",
            "REFLECTION ITERATION 2/15\n",
            "Response:\n",
            "**Architecting Iterative AI:**\n",
            "\n",
            "**1. Probabilistic Reasoning Core:** Move beyond deterministic outputs. Employ Bayesian networks, ensembles of models, or other probabilistic frameworks to generate a *distribution* of possibilities.\n",
            "\n",
            "**2. Explanation-Aware Training:** Train models not just on accuracy, but on *justifying* their reasoning. Use techniques like contrastive explanations (“This option is preferred because… but option X might be better if…”) during training.\n",
            "\n",
            "**3. Simulated User Interaction:** Integrate a \"simulated user\" during training. The AI generates options, the simulated user \"responds\" (e.g., expresses concerns, requests more information), and the AI refines its output based on that feedback.\n",
            "\n",
            "**4. Diversity-Promoting Loss Functions:** Penalize outputs that are too homogeneous. Encourage exploration of the solution space, even if it means initially lower accuracy.\n",
            "\n",
            "**Technical Challenges:**\n",
            "\n",
            "*   **Ranking Calibration:** Reliably estimating the \"efficacy\" of different options is hard. Requires robust uncertainty quantification.\n",
            "*   **Exploration vs. Exploitation:** Balancing exploration of diverse solutions with exploiting the most promising ones.\n",
            "*   **Computational Cost:** Generating and ranking multiple options is computationally expensive. Requires efficient algorithms.\n",
            "*   **Human Cognitive Load:** Presenting too many options can be overwhelming. Need to design interfaces that effectively filter and prioritize information.<end_of_turn>\n"
          ]
        }
      ]
    }
  ]
}